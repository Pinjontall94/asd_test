#!/bin/bash
# asdMetagen -- A bash script to prepare unmerged 16S V4 fastqs for
#			metagenomic analysis. 

# DEVELOPER: Sam Johnson
# LICENSE: AGPL-3.0-or-later
#	https://www.gnu.org/licenses/agpl-3.0.html
# DEPENDS: poppler-utils v0.87.0-1, bash v5.0.016-1, bbmap v38.00, mothur v1.39.5, 
# 		sratoolkit v2.10.5, cutadapt v2.8, bowtie2 v2.3.5.1
# VERSION: 0.9.0

# Set shell options (undone at end of script)
shopt -s nullglob

# Set input files
RUNTABLE=SraRunTable.txt
ACCESSION_LIST=SRR_Acc_List.txt

# Set author (from current directory)
AUTHOR=${PWD##*/}
if [[ $AUTHOR =~ "-" ]]; then
	echo "ERROR: Hyphens are not supported in dataset directory names,"\
		"due to mothur dependency."
	echo "Please rename working directory before re-running."
	exit 1
fi

# Set Dependency Module Versions & Names
SRA_MODULE=sratoolkit
SRA_MOD_VER=2.10.0

BBMAP_MODULE=bbmap
BBMAP_MOD_VER=38.82

CUTADAPT_MODULE=cutadapt
CUTADAPT_MOD_VER=2.0

MOTHUR_MODULE=mothur
MOTHUR_MOD_VER=1.39.5

BOWTIE2_MODULE=bowtie2
BOWTIE2_MOD_VER=2.3.4.1

# Define usage statement
usage(){
	echo "Usage: $0 -hldmnptT"\
		"-f <forward primer> -r <revcomp'd reverse primer>"
	echo "	-h : help"
	echo "	-l : local mode (restricts default thread count)"
	echo "	-d : download fastqs from NCBI, reading from Run Table"
	echo "	-m : skip 'Merge fastqs'"
	echo "	-n <integer> : set number of threads"
	echo "	-p <directory> : set PhiX db for bowtie2"\
		"(./PhiX_bowtie_db/phix_db by default)"
	echo "	-t <integer> : set offset on 5' end (in nucleotides)"
	echo "	-T <integer> : set offset on 3' end"
	echo "	NOTE: Ommitting forward or reverse primer will cancel"
	echo "	primer trimming on that end of the read."
	echo "		Ex: '$0 -r <primer>' will only trim the 3' primer" 
}

# Define use flags
while getopts ":hldmn:p:t:T:f:r:" FLAGS; do
	case "${FLAGS}" in
		h)
			usage
			exit 0
			;;
		l)
			LOCAL=1
			;;
		d)
			DOWNLOAD_ONLY=1
			;;
		m)
			SKIP_MERGE=1
			;;
		n)
			THREADS=$OPTARG
			echo "THREADS = $THREADS"
			;;
		p)
			PHIX_DB=$OPTARG
			echo "PHIX_DB = $PHIX_DB"
			;;
		t)
			FOR_OFFSET=$OPTARG
			echo "FOR_OFFSET = $FOR_OFFSET"
			;;
		T)
			REV_OFFSET=$OPTARG
			echo "REV_OFFSET = $REV_OFFSET"
			;;
		f)
			FORPRIME=$OPTARG
			echo "FORPRIME = $FORPRIME"
			;;
		r)
			REVPRIME=$OPTARG
			echo "REVPRIME = $REVPRIME"
			;;
		\?)
			usage
			exit 1
			;;
		*)
			usage
			exit 1
			;;
		esac
done

# Check for necessary flags before continuing
if [[ $# == 0 ]]; then
	usage
	exit 1
fi

# Check working directory for pre-existing fastq files
while IFS= read -r -d $'\0' line; do
	  fastqs_in_pwd+=("$line")
done < <(find . -maxdepth 1 -iname "*.fastq" -print0)

if [[ ! $DOWNLOAD_ONLY ]]; then
	if [[ ! -d fastqs ]] && [[ ${#fastqs_in_pwd[@]} == 0 ]]; then
		echo "$0: ERROR: No 'fastq' folder or pre-existing fastqs found!"
		echo "Please ensure both 'SraRunTable.txt' and 'SRR_Acc_List.txt'"\
			"are present, and run '$0 -d'"
		echo "Exiting..."
		exit 1
	elif [[ ${#fastqs_in_pwd[@]} > 0 ]]; then
		echo "$0: ERROR: Pre-existing fastqs found in dir: ${PWD##*/}!"
		echo "Please move all fastqs to 'fastqs' dir before re-running"\
			"${0#./} without the '-d' flag"
		echo "Exiting..."
		exit 1
#	elif [[ ! $FORPRIME ]] || [[ ! $REVPRIME ]]; then
#		echo "$0: ERROR: Primers missing! Please specify primers with"\
#			"the '-f' and '-r' flags before re-running"
#		echo "Exiting..."
#		exit 1
	fi
fi


   # Set available threads
if [[ $LOCAL ]]; then
	THREAD_DEFAULT=$(( $(nproc) - 2 ))
else
	THREAD_DEFAULT=$(nproc)
fi

if [[ ! $THREADS ]]; then
	echo "$0: Setting threads to default setting"
	THREADS=$THREAD_DEFAULT
fi
echo "$0: THREADS = $THREADS"

# ====================
# == MAIN Functions ==
# ====================


srrMunch(){
	# Short script to loop through SRRs in an SRA list, running fastq-dump, and
	# 	nicely formatting them with bbtools' reformat.sh (for now, with manual
	#	read number relabeling).

	# Deps: fastq-dump from NCBI SRA Toolkit

	# Check Run Table first for a list of 16S seqs
	# TODO: check that the following snippet accurately grabs the accession
	#    16S accession numbers from the correct column

	# Determine Run Table delimiter (commas or tabs)
	comma_count=$(grep -o "," SraRunTable.txt | wc -c)
	tab_count=$(grep -o "\t" SraRunTable.txt | wc -c)
	if ((comma_count > tab_count)); then
		echo "$comma_count commas > $tab_count tabs"
		echo "$0: Setting delimiter to commas"
		DELIMITER=","
	elif ((comma_count < tab_count)); then
		echo "$comma_count commas < $tab_count tabs"
		echo "$0: Setting delimiter to tabs"
		DELIMITER="\t"
	else
		echo "$0: Warning, Run Table not comma- or tab-separated"
		echo "Defaulting to whitespace..."
		DELIMITER=" "
	fi

	# Extract all 16S accession numbers (if determinable)
	awk -F "$DELIMITER" '
		# Loop over column 2, set column with valid accession number as target
		NR==2 {
			for(i=1;i<=NF;i++){
				if($i ~ "[A-Z]RR[0-9]{4,6}"){ target=i }
			}
		}

		# Print all entries in the target column if they have '16S' in their row
		#    (skipping the header row, of course)
		NR>1 && /16S/ { print $target }
		' SraRunTable.txt > 16S_list.txt.temp

	# Set which list to loop fastq-dump over
	if [[ -s 16S_list.txt.temp ]]; then
		echo "$0: awk filter successful, setting 16S_list.txt.temp to \$READ_LIST"
		READ_LIST=16S_list.txt.temp	
	else
		echo "$0: awk filter failed to find 16S seqs,"\
			"leaving filtering duties to cutadapt.."
		READ_LIST=$ACCESSION_LIST
	fi

	echo "Looping through $READ_LIST with sratoolkit and" \
		"unpacking fastqs..."

	# Loop fastq-dump over Accession Number list
	pathTester fastq-dump $SRA_MODULE $SRA_MOD_VER
	while read accno; do
		fastq-dump --split-3 --gzip $accno 2>>fastq-dump.err
	done < $READ_LIST
	gzip -d *.fastq.gz
	[[ ! -f 16S_list.txt.temp ]] || rm -v 16S_list.txt.temp

	# Parse fastq-dump.err files for fastq-dump download errors,
	# store matching accession numbers in array
	fastq_err=()
	while IFS= read -r -d $'\0' line; do
		fastq_err+=("$line")
	done < <(awk '/fastq-dump.*err:/ { print $NF }' fastq-dump.err)

	# If fastq-dump error accnos are found, delete the messed up fastqs
	# 	re-download, and re-decompress them
	if [[ ${#fastq_err[@]} > 0 ]]; then
		for i in ${fastq_err[*]}; do
			rm $i*.fastq
			fastq-dump --split-3 --gzip $i
			gzip -d $accno*.fastq.gz
		done
	else
		echo "No download errors found for fastq-dump"
		rm -v fastq-dump.err
	fi

	# Create output directory
	mkdir fastqs
	mv -v *.fastq fastqs
}


mergeSeqs(){
	# merge all fastqs in the current directory with bbmerge.sh

	# INPUT: sufRegex(), bbmerge.sh(), fastqs/
	# OUTPUT: merged_fastqs/

	# Deps: bbmerge.sh

	# Set input type
	in_type=fastq

	# Move input files to working directory
	inPrep fastqs

	pathTester bbmerge.sh $BBMAP_MODULE $BBMAP_MOD_VER

	echo "Checking forward and reverse fastq read counts"\
		"prior to merging"

	# Merge all _1 & _2 fastqs
	for i in ${in_file[@]}; do
		if [[ $i =~ _1.fastq ]]; then
			# Select forward reads in the for loop,
			#	then designate the reverse from $i
			REV=${i//_1.fastq/_2.fastq}
			READ_NAME=${i%_1.fastq}
			OUT_FILE=${i%_1.fastq}.merged.fastq
			# Make sure the read numbers are identical between
			#	forward and reverse
			echo "Checking: $i $REV"
			F_READ_NUM=$(grep -c "@$READ_NAME" $i)
			R_READ_NUM=$(grep -c "@$READ_NAME" $REV)
	
			if [[ $F_READ_NUM == $R_READ_NUM ]]; then
				echo "Read counts match; "\
					"Now merging: $i and $REV"
				echo "Merge out file: $OUT_FILE"
				bbmerge.sh in1="$i" in2="$REV" out="$OUT_FILE"
			else
				echo "Mismatch found, delete reads for $READ_NAME and "\
					"re-run fastq-dump before proceeding"
				exit 0
			fi
		elif [[ ! $i =~ _(1|2).fastq ]]; then # Matches reads w/o "_1" or "_2"
			echo "Renaming pre-merged read $i to ${i//fastq/merged.fastq}"
			mv -v $i ${i%.fastq}.merged.fastq
		else
			continue
		fi
	done
	
	# Move inputs and outputs back to corresponding directories
	out_type="merged.fastq"
	outPrep fastqs merged_fastqs
}


q2aReformat(){
	# DESCRIPTION: Reformats all fastq files in current directory to fasta

	# Deps: bbtools 'reformat' tool

	# Set input type
	in_type=fastq

	# Move input files to working directory
	if [[ $SKIP_MERGE ]]; then
		inPrep fastqs
	else
		inPrep merged_fastqs
	fi

	pathTester reformat.sh $BBMAP_MODULE $BBMAP_MOD_VER

	echo "Reformatting merged fastqs files to fasta format..."
	for i in ${in_file[@]}; do
		reformat.sh in=$i out=${i%.fastq}.fasta
	done

	# Move inputs and outputs back to corresponding directories
	out_type=fasta
	outPrep merged_fastqs merged_fastas
}


groupFormatter(){
	# Description: Scans current directory for .fasta files, and
	#              formats them for use with the R package Mothur's
	#              'make.group()' command

	# Set input type
	in_type=fasta

	# Move input files to working directory
	inPrep merged_fastas

	# Load executable if necessary
	pathTester mothur $MOTHUR_MODULE $MOTHUR_MOD_VER

	# Create hyphen-delimited lists for fastas and groups
	formatter_fastas=$(joinBy - ${in_file[*]})
	for i in ${in_file[@]}; do
		group_array+=("$AUTHOR"_"${i%%.*}")
	done
	formatter_groups=$(joinBy - ${group_array[*]})

	# Set mothur command parameters and run mothur
	group_params=("fasta=$formatter_fastas," "groups=$formatter_groups,"\
		"output=$AUTHOR.groups")
	mothur <(mothurBatch make group "${group_params[*]}")

	# Move inputs and outputs back to corresponding directories
	out_type=$AUTHOR.groups
	outPrep merged_fastas .
}


trimLoop(){
	# Takes the primer patterns from command line,
	# inputs to cutadapt, and loops through all fasta # files in $(pwd)

	# INPUT: cutadapt(), $FORPRIME, $REVPRIME, *.merged.fasta
	# OUTPUT: *.trimmed.fasta
	
	# Set input type
	in_type=fasta

	# Move input files to working directory
	inPrep merged_fastas
	pathTester cutadapt $CUTADAPT_MODULE $CUTADAPT_MOD_VER

	echo "Trimming primers..."
	echo "FORPRIME = $FORPRIME \t REVPRIME = $REVPRIME"

	for i in ${in_file[@]}; do
		m=${i%.fasta}
		if [[ $FORPRIME ]]; then
			echo "FORPRIME = $FORPRIME"
			cutadapt -g $FORPRIME\
				-o $m.temp.fasta $i\
				--discard-untrimmed
		fi

		if [[ $REVPRIME ]]; then
			echo "REVPRIME = $REVPRIME"
			cutadapt -a $REVPRIME\
				-o $m.trimmed.fasta $m.temp.fasta\
				--discard-untrimmed
		fi
	done
	rm -v *.temp.fasta
	
	# Move inputs and outputs back to corresponding directories
	out_type=trimmed.fasta
	outPrep merged_fastas trimmed_fastas
}


offsetTrim(){
	# Apply offset (if applicable)
	# 
	pathTester cutadapt $CUTADAPT_MODULE $CUTADAPT_MOD_VER

	##TODO: Clean up input and output mess in this function
	# Set input type
#	in_type=fasta

	# Move input files to working directory
#	inPrep trimmed_fastas

	if [[ ! $FORPRIME ]] && [[ ! $REVPRIME ]]; then
		echo "TEST 1"
		in_type=fasta
		inPrep merged_fastas
	else
		echo "TEST 2"
		in_type=trimmed.fasta
		inPrep trimmed_fastas
	fi

	for i in ${in_file[@]}; do
		PRE_OFFSET=${i%.fasta}.preoffset.fasta
		OFFSET_TEMP=${i%.fasta}.offset.temp.fasta
		OUTPUT=${i%.fasta}.offset.fasta
		if [[ $FOR_OFFSET ]] && [[ $REV_OFFSET ]]; then
			echo "Trimming $FOR_OFFSET nucleotides"\
				"from 5' end of $i"
			cutadapt -u $FOR_OFFSET -o $OFFSET_TEMP $i

			echo "Trimming $REV_OFFSET nucleotides"\
				"from 3' of $OFFSET_TEMP"
			cutadapt -u -$REV_OFFSET -o $OUTPUT $OFFSET_TEMP
		elif [[ $FOR_OFFSET ]]; then
			echo "Trimming $FOR_OFFSET nucleotides"\
				"from 5' end of $i"
			cutadapt -u $FOR_OFFSET -o $OUTPUT $i
		else
			echo "Trimming $REV_OFFSET nucleotides"\
				"from 3' of $i"
			cutadapt -u -$REV_OFFSET -o $OUTPUT $i
		fi
	done

	# Remove temp files
	rm -v *.temp.fasta 

	# Move inputs and outputs back to corresponding directories
	out_type=offset
	if [[ ! $FORPRIME ]] && [[ ! $REVPRIME ]]; then
		outprep merged_fastas offset_fastas
#		mv *.merged.fasta merged_fastas
#		mkdir offset_fastas
#		mv *.offset.fasta offset_fastas
	else
		outPrep trimmed_fastas offset_fastas
#		mv *.trimmed.fasta trimmed_fastas
#		mkdir offset_fastas
#		mv *.offset.fasta offset_fastas
	fi
}

phixScreen(){
	# DESCRIPTION: Takes in a fasta file, phix databases in a directory named
	# 	$PWD/phix_db/ and screens for PhiX contamination

	# INPUT: bowtie2(), (trimmed_fastas/|offset_fastas/), $PHIX_DB
	# OUTPUT: *.screened.fasta, *.merged.PhiX, *.merged.bowtie
	# Deps: bowtie2
	
	# Set input type
	if [[ -d offset_fastas ]]; then
		in_type=offset.fasta
	else
		in_type=trimmed.fasta
	fi

	# Set input files and directories
	inPrep ${in_type%.fasta}\_fastas

	pathTester bowtie2 $BOWTIE2_MODULE $BOWTIE2_MOD_VER

	# Set default PhiX db directory (if none provided)
	if [[ ! $PHIX_DB ]]; then
		PHIX_DB=phix_db/PhiX_bowtie_db
	fi

	# Loop bowtie2 over processed fastas
	echo "Screening for PhiX contamination"
	for i in ${in_file[@]}; do
		bowtie2 -f $i -x $PHIX_DB\
			-S ${i%%.*}.merged.bowtie\
			--un ${i%%.*}.screened.fasta\
			--al ${i%%.*}.merged.PhiX\
			--local -p $THREADS
	done

	# Once complete, generate list of reads to be screened out
	for i in *.merged.PhiX; do
		if [[ -s $i ]]; then
			echo "generating PhiX accession number file..."
			# Old grep command, probably won't work on multiple
			# 	files without generating "<filename>:<accno>"
			# grep ">" *merged.PhiX >> PhiX.accnos

			# [Do accnos in *.merged.PhiX start with ">"?]
			# 	also, this works with *.merged.PhiX,
			#	not just a single file "merged.PhiX"
			grep -Eo "[A-Z]{3,6}[0-9]+\.[0-9]+" *.merged.bowtie \
			| awk -F: '{ print $2 }' >> PhiX.accnos
		else
			rm $i
		fi
	done

	# Concatenate PhiX screened fastas to single file
	# (identified by $AUTHOR)
	cat *.screened.fasta > $AUTHOR.concat.fasta

	# Create output folder for screened fastas (separate from other PhiX outputs)
	mkdir screened_fastas && mv *.screened.fasta screened_fastas

	# Remove unneeded ".bowtie" outs
	rm *.merged.bowtie

	# Move inputs and outputs back to corresponding directories
	out_type=("merged.PhiX" "merged.bowtie" "PhiX.accnos")
	outPrep ${in_type%.fasta}\_fastas PhiX_outs
}


mothurScreen(){
	# Runs mothur against screening_batch.txt to screen concat'd fasta

	# INPUT: mothur(), PhiX.accnos, $AUTHOR.concat.fasta,
	#		$AUTHOR.groups
	# OUTPUT: *.good.* *.bad.*

	pathTester mothur $MOTHUR_MODULE $MOTHUR_MOD_VER
	screen_fasta=$AUTHOR.concat.fasta
	screen_groups=$AUTHOR.groups

	# Remove PhiX contamination
	if [[ -s PhiX_outs/PhiX.accnos ]]; then
		remove_params=("fasta=$screen_fasta,"\
			"group=$screen_groups,"\	# Not needed by mothur?
			"accnos=PhiX/PhiX.accnos")
		mothur <(mothurBatch remove seqs "${remove_params[*]}")
		rm -v phix_batch.txt
	else
		echo "PhiX.accnos is empty, skipping..."
	fi

	if [[ ! $screen_fasta ]] || [[ ! $screen_groups ]]; then
		echo "$0: ERROR: Zero-length input variables detected!"
		exit 1
	else
		screen_params=("fasta=$screen_fasta," "group=$screen_groups,"\
			"minlength=200," "maxlength=300," "maxambig=0,"\
			"maxhomop=8")
		summary_params=("fasta=current," "processors=$THREADS")
		mothurBatch screen seqs "${screen_params[*]}" > screening_batch.txt
		mothurBatch summary seqs "${summary_params[*]}" >> screening_batch.txt
		mothurBatch count groups "group=current" >> screening_batch.txt 
	
		echo "cat'ing screening_batch.txt"
		cat screening_batch.txt
		mothur screening_batch.txt 
		rm screening_batch.txt
	fi

	out_type=(".bad" ".good")
	outPrep PhiX_fastas .
}


groupSplit(){
	# Splits the screened fasta to prepare for fasta header relabeling,
	# 	necessary for vsearch later

	in_type=good.fasta
	inPrep .

	pathTester mothur $MOTHUR_MODULE $MOTHUR_MOD_VER
	for i in *.fasta; do
		if [[ $i =~ good ]]; then
			GOOD_FASTA=$i
		fi
	done; 
#	GOOD_FASTA=$AUTHOR.concat.fasta
	for i in *.groups; do
		if [[ $i =~ good ]]; then
			GOOD_GROUPS=$i
		fi
	done
#	GOOD_GROUPS=$AUTHOR.groups
	
	echo "GOOD_FASTA=$GOOD_FASTA, GOOD_GROUPS=$GOOD_GROUPS"
	
	split_params=("fasta=$GOOD_FASTA,"\
		"group=$GOOD_GROUPS")
	mothur <(mothurBatch split groups "${split_params[*]}")

	# Rename output fastas to reasonable names
	for i in *.fasta; do
		if [[ $i =~ ".$AUTHOR" ]]; then
			# Remove everything up to "concat."
			# (i.e. result: author_year_accno.fasta)
			echo "Renaming output files to"\
				"format: author_year_accno.fasta"
			mv -v $i ${i#*good.}
		fi
	done

	out_type=$AUTHOR\_
	outPrep . split_fastas
}


fastaHeaderrelabel(){
	# Takes a fasta file labeled <author>_<year>_<accno>.fasta
	# 	and relabels headers for use with vsearch
	#
	# e.g.:
	# ">SRR10007909.1201 1201 length=251"
	# 		|
	# 		V
	# ">Li_2019_SRR10007909_1;barcodelabel=Li_2019_SRR10007909;"
		

	# INPUT:  $AUTHOR_*.fasta
	# OUTPUT: *.barcoded.fasta

	in_type=fasta
	inPrep split_fastas

	for i in ${in_file[@]}; do
		awk -v NAME_STRIPPED="${i%.fasta}" '{
			# Count every header line
			if (/^>/) COUNT+=1 

			# Define new header format
			VSEARCH_HEADER=">"NAME_STRIPPED"_"COUNT"\;barcodelabel="NAME_STRIPPED"\;"

			# Relabel everything after ">" with new header
			gsub(/^>.*/, VSEARCH_HEADER)
			print;
		}' $i > ${i%.fasta}.bar.fasta 2>/dev/null
	done

	# Concatenate output files to single barcoded fasta
	# (also identified by $AUTHOR)
	cat *.bar.fasta > $AUTHOR.barcoded.fasta

	out_type=bar.fasta
	outPrep split_fastas relabeled_fastas
}


garbageDay(){
	# Delete unneeded outputs and directories to clean up final output

	rm $AUTHOR.*.bad.*

	# Remove PhiX_outs entirely, if it's empty
	# (equivalent to "rmdir PhiX_outs" without unnecessary errors)
	find PhiX_outs -maxdepth 0 -empty -exec rmdir {} \;

	# Move all remaining author files to outputs dir
	mkdir asdMetagen_final && mv $AUTHOR.* asdMetagen_final

	# Move logs to log dir
	mkdir asdMetagen_logs && mv *.log* asdMetagen_logs
}

# --------------------
# -- Util Functions --
# --------------------

nucRegex(){
	# Convert degenerate bases to regex patterns

	# INPUT: string
	# OUTPUT: string

	echo $1 | sed '
	s/W/(A|T)/
	s/S/(C|T)/
	s/M/(A|C)/
	s/K/(G|T)/
	s/R/(A|G)/
	s/Y/(C|T)/
	s/B/[CGT]/
	s/D/[AGT]/
	s/H/[ACT]/
	s/V/[ACG]/
	s/N/./
	s/X/./
	'
}


pathTester(){
	# Test if cutadapt is in PATH, and load if necessary
	# Usage: pathTester <executable> <module (opt.)> <version (opt.)>

	if [[ $(type -t $1) ]]; then
		echo "$0: $1 is in PATH"
	elif [[ $(type -t ./$1) ]]; then
		echo "$0: ERROR: $1 is in directory, but not PATH"
		echo "Exiting..."
		exit 1
	elif [[ $(type -t module) ]]; then
	    	echo "$0: $1 not found in PATH"
		echo "$0: Command: module load $2/$3"
		module load $2/$3
	else
		echo "$0: ERROR: No module, local executable, or path"\
			"executable found. Aborting..."
		exit 1
	fi
}


sufRegex(){
	# Takes in unmerged fastq ending in _1|_R1,
	# 	and returns suffic regex and the name
	# 	of the reverse read

	# INPUT: *1.fastq
	# OUTPUT: $REV
	# [Maybe just change incoming "_R1" to "_1" so we don't have to deal
	# 	with it in the first place]

	if [[ "$1" =~ "_1.fastq" ]]; then
		REV=${1//_1.fastq/_2.fastq}
	elif [[ "$1" =~ "_R1.fastq" ]]; then
		REV=${1//_R1.fastq/_R2.fastq}
	else
		echo "$0: ERROR: Expected merge suffices not found" >&2
		exit 1
	fi
}


joinBy(){
	# Takes first argument as new delimiter, then echoes all following
	# 	arguments with that delimiter
	# Usage: joinBy <separator> <arg1> [...] <argN>

	OIFS=$IFS
	IFS=$1

	shift
	echo "$*"

	IFS=$OIF
}


mothurBatch(){
	# Wrapper script for generating simple mothur commands, prints
	# 	command to stdout to create batch files

	# Note: If you have many parameters, put them in an array!
	# Ex: EX_PARAMS+=("fasta=blah.fasta,"\
	#	"group=blah.groups")
	#
	# Just make sure to refer to them with * expansion, not @ expansion,
	#	and enclose in double quotes!
	# e.g. mothurBatch doggo play "${EX_PARAMS[*]}"
	# 	|==> doggo.play(fasta=blah.fasta, group=blah.groups)

	COMMAND=$1.$2
	PARAMS="$3"
	echo "$COMMAND($PARAMS)"
}

inPrep(){
	# Takes input directory argument and global input array, and
	#	moves relevant input files to working directory
	# Usage: inPrep <IN_DIR>
	
	# Set types and directories
	IN_DIR=$1

	# Set input files
	for file in $IN_DIR/*; do
		# If files in the input directory match the
		#	input type pattern, add them to the input
		#	file array
		for i in ${in_type[*]}; do
			if [[ -f $file ]] && [[ $file =~ $i ]]; then
				echo "$AUTHOR/${file##*/} matches input type $i;"\
					"adding to input file list"
				in_file+=("${file##*/}")
				break
			fi
		done
	done

	# Exit if input file array is still empty
	if [[ ${#in_file[@]} == 0 ]]; then
		echo "$0: ERROR"
		echo "No files found in input directory: $AUTHOR/$IN_DIR,"\
			"or none matching input type: $in_type"
		echo "Exiting"
		exit 1
	fi

	# Move input files to working directory
	for i in ${in_file[@]}; do
		mv -v $IN_DIR/$i .
	done
}


outPrep(){
	# Moves input and output files to corresponding directories
	#	(also creates the output directory)
	# Usage: outPrep <input dir> <output dir>
 
	# Set input and output directories 
	IN_DIR=$1
	OUT_DIR=$2
	
	# Create output directory
	if [[ ! -d $OUT_DIR ]]; then
		mkdir $OUT_DIR
	fi

	# Add all files matching the output types to the output file array
	for file in *; do
		# If files in the working directory match the
		#	output type pattern, add them to the output
		#	file array
		for i in ${out_type[@]}; do
			if [[ -f $file ]] && [[ $file =~ $i ]]; then
				echo "$AUTHOR/$file matches output type $i;"\
					"adding to output file list"
				out_file+=("$file")
				break
			fi
		done
	done

	# Move outputs to corresponding directories
	if [[ ${#out_file[@]} != 0 ]]; then
		mv -v ${out_file[*]} $OUT_DIR
	else
		# Print warning if output file array is still empty
		echo "$0: Warning: No files matching output types: ${out_type[@]}"
	fi

	# Move input files back to corresponding directories
	mv -v ${in_file[*]} $IN_DIR


	
	# Reset input and output arrays
	unset in_file out_file in_type out_type
}

# =============	
# == M A I N ==
# =============

main(){
	logfile=metagen.$(date +%d_%H_%M_%S).log
	date -u > $logfile

	if [[ $DOWNLOAD_ONLY ]]; then
		srrMunch
		exit 0
	else
		[[ -d fastqs ]] || mkdir fastqs
	fi

	# Merge forward and reverse reads
	if [[ $SKIP_MERGE ]]; then
		#TODO: Clean this up so it's not in main
		echo "Skipping merge stage"
#		echo "Renaming fastqs and fastq directory for pipeline compatibility"
#		for i in fastqs/*.fastq; do
#			mv $i ${i%.fastq}.merged.fastq
#		done
#		mv fastqs merged_fastqs
	else
		mergeSeqs
	fi

	q2aReformat
	groupFormatter

	# Trim primers
	if [[ $FORPRIME ]] || [[ $REVPRIME ]]; then
		trimLoop
	fi

	# Trim nucleotide offset
	if [[ $FOR_OFFSET ]] || [[ $REV_OFFSET ]]; then
		offsetTrim
	else
		echo "No offset specified, make sure this"\
			"is the right target region! (In this case: 520F-802R)"
	fi

	phixScreen
	mothurScreen
	groupSplit
	fastaHeaderrelabel
	garbageDay
	date -u >> $logfile
}

main

shopt -u nullglob
