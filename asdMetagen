#!/bin/bash
# asdMetagen -- A bash script to prepare unmerged 16S V4 fastqs for
#			metagenomic analysis. 

# AUTHOR: Sam Johnson
# LICENSE: GNU Affero General Public License 
#	https://www.gnu.org/licenses/agpl-3.0.html
# DEPENDS: poppler-utils v0.87.0-1, bash v5.0.016-1, bbmap v38.00, mothur v1.39.5, 
# 		sratoolkit v2.10.5, cutadapt v2.8, bowtie2 v2.3.5.1
# VERSION: 0.9.0

# Set shell options (undone at end of script)
shopt -s nullglob

# Set input files
RUNTABLE=SraRunTable.txt
ACCESSION_LIST=SRR_Acc_List.txt

# Set author (from current directory)
AUTHOR=${PWD##*/}

# Set Dependency Module Versions & Names
SRA_MODULE=sratoolkit
SRA_MOD_VER=2.10.0

BBMAP_MODULE=bbmap
BBMAP_MOD_VER=38.82

CUTADAPT_MODULE=cutadapt
CUTADAPT_MOD_VER=2.0

MOTHUR_MODULE=mothur
MOTHUR_MOD_VER=1.39.5

BOWTIE2_MODULE=bowtie2
BOWTIE2_MOD_VER=2.3.4.1

# Define usage statement
usage(){
	echo "Usage: $0 -hlDMnpdctT"\
		"-f <forward primer> -r <revcomp'd reverse primer>"
	echo "	-h : help"
	echo "	-l : local mode (restricts default thread count)"
	echo "	-DM : skip 'Download fastqs' | 'Merge fastqs'"
	echo "	-n <integer> : set number of threads"
	echo "	-p <directory> : set PhiX db for bowtie2"\
		"(./PhiX_bowtie_db/phix_db by default)"
	echo "	-d \"<delimiter>\" : set delimiter for run table (Note the double quotes!)"
	echo "	-c <integer> : set column number for run table accnos"
	echo "	-t <integer> : set offset on 5' end (in nucleotides)"
	echo "	-T <integer> : set offset on 3' end"
	echo "	NOTE: Ommitting forward or reverse primer will cancel"
	echo "	primer trimming on that end of the read."
	echo "		Ex: '$0 -r <primer>' will only trim the 3' primer" 
}

# Define use flags
while getopts "hlDMn:p:d:c:t:T:f:r:" FLAGS; do
	case "${FLAGS}" in
		h)
			usage
			exit 0
			;;
		l)
			LOCAL=1
			;;
		D)
			SKIP_DOWNLOAD=1
			;;
		M)
			SKIP_MERGE=1
			;;
		n)
			THREADS=$OPTARG
			echo "THREADS = $THREADS"
			;;
		p)
			PHIX_DB=$OPTARG
			echo "PHIX_DB = $PHIX_DB"
			;;
		d)
			DELIMITER=$OPTARG
			echo -e "DELIMITER = $DELIMITER"
			;;
		c)
			COLUMN=$OPTARG
			echo "Run Table accession number column: $COLUMN"
			;;
		t)
			FOR_OFFSET=$OPTARG
			echo "FOR_OFFSET = $FOR_OFFSET"
			;;
		T)
			REV_OFFSET=$OPTARG
			echo "REV_OFFSET = $REV_OFFSET"
			;;
		f)
			FORPRIME=$OPTARG
			echo "FORPRIME = $FORPRIME"
			;;
		r)
			REVPRIME=$OPTARG
			echo "REVPRIME = $REVPRIME"
			;;
		esac
done

# Set available threads 
if [[ $LOCAL == 1 ]]; then
	THREAD_DEFAULT=$(( $(nproc) - 2 ))
else
	THREAD_DEFAULT=$(nproc)
fi

if [[ ! $THREADS ]]; then
	echo "$0: Setting threads to default setting"
	THREADS=$THREAD_DEFAULT
fi

# Initialize arrays
	fasta_array=()
	group_array=()

# Set "executable in path?" variable (for legibility)
inPath=


# ====================
# == MAIN Functions ==
# ====================

sraFinder(){
	# Simple grep parser for all NCBI SRA accession numbers in pdf files in the working directory
	# usage: <sraFinder.sh>

	if [ ! -f "SRR_Acc_List.txt" ] && [ ! -f "SraRunTable.txt" ]; then
		for f in *.pdf; do
			pdftotext $f # convert pdf files to parsable txt files
			r=${f%.pdf}.txt
			PATTERN="[A-Z]{3,}[[:digit:]]{5,}"
			if [[ -n $(grep -Eo "$PATTERN" $r) ]]; then
				grep -Eo "[A-Z]{3,}[[:digit:]]{5,}" $r \
					> ${r%.txt}.sra
				# echo anything in txt that has =>3 capitals, 
				#	followed by => 5 numbers, into a new 
				#	file with a ".sra" extension (regex: 
				#	[A-Z]{3,}[[:digit:]]{5,} )
			else
				echo "No valid accession number found"\
					"in file: $f"
			fi
	
			# Make primers file for screening [WORK IN PROGRESS]
			#grep -i -P -A 1 "[0-9]{3}f" \
			#	> $(basename -- $f .pdf)_primers.txt
			#grep -i -P -A 1 "[0-9]{3}r" \
			#	>> $(basename -- $f .pdf)_primers.txt
			rm $r
		done
	else
		echo "$0: Accession List and Run Table found,"\
			"continuing..."
fi

}


srrMunch(){
	# Short script to loop through SRRs in an SRA list, running fastq-dump, and
	# 	nicely formatting them with bbtools' reformat.sh (for now, with manual
	#	read number relabeling).

	# INPUT: fastq-dump(), $ACCESSION_LIST
	# OUTPUT: *.fastq

	# Check Run Table first for a list of 16S seqs
	[[ $COLUMN ]] || COLUMN=1
	if [[ $DELIMITER ]]; then
		echo "$0: Running command:"
		echo -e "awk -F $DELIMITER -v c=$COLUMN '/16S/ { print $c }'"\
			"$RUNTABLE > 16S_list.txt.temp"
		awk -F $DELIMITER -v c=$COLUMN '/16S/ { print $c }' $RUNTABLE\
			> 16S_list.txt.temp
	else
		echo "$0: Running command:"
		echo "awk -v c=$COLUMN '/16S/ { print $c }'"\
			"$RUNTABLE > 16S_list.txt.temp"
		awk -v c=$COLUMN '/16S/ { print $c }' $RUNTABLE\
			> 16S_list.txt.temp
	fi

	# Set which list to loop fastq-dump over
	if [[ -s 16S_list.txt.temp ]]; then
		READ_LIST=16S_list.txt.temp	
	else
		echo "$0: awk filter failed to find 16S seqs,"\
			"leaving filtering duties to cutadapt.."
		READ_LIST=$ACCESSION_LIST
	fi

	echo "$0: Looping through $READ_LIST with sratoolkit and" \
		"unpacking fastqs..."

	# Loop fastq-dump over Accession Number list
	pathTester fastq-dump $SRA_MODULE $SRA_MOD_VER
	while read accno; do
		biExec fastq-dump --split-3 --gzip $accno 2>>fastq-dump.err
		gzip -d $accno*.fastq.gz
	done <$READ_LIST
	[[ ! -f 16S_list.txt.temp ]] || rm -v 16S_list.txt.temp

	# TODO: Parameterize fastq-dump call?
	# Parse fastq-dump.err files for fastq-dump download errors, 
	# store matching accession numbers in array
	fastq_err=()
	while IFS= read -r -d $'\0' line; do
		fastq_err+=("$line")
	done < <(awk '/fastq-dump.*err:/ { print $NF }' fastq-dump.err)

	# If fastq-dump error accnos are found, delete the messed up fastqs
	# 	re-download, and re-decompress them
	if [[ ${#fastq_err[@]} > 0 ]]; then
		for i in ${fastq_err[*]}; do
			rm $i*.fastq
			biExec fastq-dump --split-3 --gzip $i
			gzip -d $accno*.fastq.gz
		done
	else
		echo "$0: No download errors found for fastq-dump" 
		rm -v fastq-dump.err
	fi

	# Create output directory
	mkdir fastqs
	mv -v *.fastq fastqs
}


16sExtractor(){
	# Description: takes an SraRunTable file from NCBI and outputs all
	# 		SRR's that contain "16S"

	# INPUT: fastq-dump, $RUNTABLE, *.fastq
	# OUTPUT: filter/, *.fastq

	echo "$0: Filtering out non-16S fastqs by runtable metadata..."

	
	mkdir 16S_temp filter
	if [[ $COLUMN ]]; then
		awk -v c=$COLUMN '/16S/ { print $c }' $RUNTABLE \
			> 16S_list.txt.temp
	else
		awk '/16S/ { print $1 }' $RUNTABLE \
			> 16S_list.txt.temp
	fi
	if [[ -s 16S_list.txt.temp ]]; then
		# Create list of 16S seqs from the runtable
		while read line; do
			#echo "$line.fastq"
			eval mv -v fastqs/$line*.fastq 16S_temp # Move 16S seqs to temp dir
		done < 16S_list.txt.temp
		# Move the non-match seqs to the filter, or remove filter if all seqs match
		filter_array=()
		while IFS= read -r -d $'\0' line; do
			filter_array+=("$line")
		done < <(find fastqs -maxdepth 1 -name "*.fastq" -print0)
		if [[ ${#filter_array[@]} > 0 ]]; then
			# move any remaining fastqs to filter
			mv -v fastqs/* filter
		else
			# ...or delete filter/ if there aren't any left
			rmdir filter
		fi
	else
		echo "$0: awk filter failed to find 16S seqs,"\
			"leaving filtering duties to cutadapt.."
	fi

	rm -v 16S_list.txt.temp
	mv -v 16S_temp/* fastqs && rmdir 16S_temp
}


mergeSeqs(){
	# DESCRIPTION: A simple script that runs bbmerge.sh to merge all fastqs in the current
	# 	directory.

	# INPUT: sufRegex(), bbmerge.sh(), fastqs/
	# OUTPUT: merged_fastqs/

	# Deps: bbmerge.sh
	# NOTE: RUN AFTER: --- srr_munch.sh
	#	RUN BEFORE: -- q2a_reformat.sh

	
	pathTester bbmerge.sh $BBMAP_MODULE $BBMAP_MOD_VER

	echo "$0: Checking forward and reverse fastq read counts"\
		"prior to merging"

	# Merge all _1 & _2 fastqs
	for i in fastqs/*_1.fastq; do
		#sufRegex $i # Create $REV from $i (unnecessary?)		
		REV=${i//_1.fastq/_2.fastq}
		READ_NAME=${i%_1.fastq}
		OUT_FILE=${i%_1.fastq}.merged.fastq
		# Make sure the read numbers are identical between forward
		# 	and reverse
		# TODO:[Clean this up, just check the first few times for efficiency]
		echo "Checking: $i $REV"
		F_READ_NUM=$(grep -c "@$READ_NAME" $i)
		R_READ_NUM=$(grep -c "@$READ_NAME" $REV)

		if [[ $F_READ_NUM == $R_READ_NUM ]]; then
			echo "$0: Read counts match; "\
				"Now merging: $i and $REV"
			echo "$0: Merge out file: $OUT_FILE"
			biExec bbmerge.sh in1="$i" in2="$REV" out="$OUT_FILE"
		else
			echo "Mismatch found, delete reads for $READ_NAME and "\
				"re-run fastq-dump before proceeding"
			exit 0
		fi
	done
	
	# Create output directory
	mkdir merged_fastqs
	mv -v fastqs/*.merged.fastq merged_fastqs

	#outStore merged_fastqs "fastqs/*.merged.fastqs"
}


q2aReformat(){
	# DESCRIPTION: Reformats all fastq files in current directory to fasta

	# INPUT: reformat.sh(), merged_fastqs/
	# OUTPUT: *.merged.fasta

	# Deps: bbtools 'reformat' tool

	# NOTE: RUN AFTER: --- mergeSeqs
	#	RUN BEFORE: -- groupFormatter
	pathTester reformat.sh $BBMAP_MODULE $BBMAP_MOD_VER

	echo "$0: Reformatting merged fastqs files to fasta format..."
	for i in merged_fastqs/*; do
		biExec reformat.sh in=$i out=${i%.fastq}.fasta
	done

	# Create output directory
	mkdir merged_fastas
	mv -v merged_fastqs/*.fasta merged_fastas
	#outStore merged_fastas "merged_fastqs/*.fasta"
}


batchArrayadder(){
	# Description: Add fastas to array

	# INPUT: $1, fasta_array, group_array 
	# OUTPUT: fasta_array, group_array


	for i in $1; do
		echo "Adding $i to fastas array"
		fasta_array+=("$i")
		echo "Adding $AUTHOR_${i%%.*} to groups array"
		group_array+=("$AUTHOR"_"${i%%.*}")
	done
}


groupFormatter(){
	# Description: Scans current directory for .fasta files, and
	#              formats them for use with the R package Mothur's
	#              'make.group()' command

	# INPUT: batchArrayadder(), joinBy(), mothur(), fasta_array, group_array
	# OUTPUT: $AUTHOR.groups, mothur.*.logfile

	# NOTE: RUN AFTER: --- q2a_reformat.sh
	# 	RUN BEFORE: -- [mothur merge script]

	# Ex: mothur > make.group(fasta=sample1.fasta-sample2.fasta-sample3.fasta, groups=A-B-C)

	pathTester mothur $MOTHUR_MODULE $MOTHUR_MOD_VER
	OUT_FILE=$AUTHOR.groups

	# Move fastas into working directory
	mv -v merged_fastas/* .

	# Add fastas and group names to their corresponding arrays
	batchArrayadder "*.fasta"

	# Create "-"-separated strings from the arrays for use with mothur
	FORMATTER_FASTAS=$(joinBy - ${fasta_array[*]})
	FORMATTER_GROUPS=$(joinBy - ${group_array[*]})

	#TODO: Rewrite with mothurBatch
	echo "make.group(fasta=$FORMATTER_FASTAS,"\
		"groups=$FORMATTER_GROUPS,"\
		"output=$AUTHOR.groups)"\
		> group_batch.temp.txt
		
	biExec mothur group_batch.temp.txt 
	rm group_batch.temp.txt
	
	# Move fastas back into their dedicated directory
	mv -v *.fasta merged_fastas
}


trimLoop(){
	# Takes the primer patterns from command line,
	# inputs to cutadapt, and loops through all fasta # files in $(pwd)

	# INPUT: cutadapt(), $FORPRIME, $REVPRIME, *.merged.fasta
	# OUTPUT: *.trimmed.fasta
	pathTester cutadapt $CUTADAPT_MODULE $CUTADAPT_MOD_VER

	echo "$0: Trimming primers..."
	echo "$0: FORPRIME = $FORPRIME \t REVPRIME = $REVPRIME"
	# Move fastas into working directory
	mv -v merged_fastas/* .

	for i in *.fasta; do
		m=${i%.fasta}
		if [[ $FORPRIME ]]; then
			biExec cutadapt -g $FORPRIME\
				-o $m.temp.fasta $i\
				--discard-untrimmed
		fi

		if [[ $REVPRIME ]]; then
			biExec cutadapt -a $REVPRIME\
				-o $m.trimmed.fasta $m.temp.fasta\
				--discard-untrimmed
		fi
	done
	rm -v *.temp.fasta
	
	# Create output directory
	mkdir trimmed_fastas

	# Move inputs and outputs to dedicated directories
	mv -v *.trimmed.fasta trimmed_fastas
	mv -v *.merged.fasta merged_fastas
}


offsetTrim(){
	# Apply offset (if applicable)
	# 
	# TODO: This function is boilerplate and ugly as all get out,
	#	clean it up later!
	pathTester cutadapt $CUTADAPT_MODULE $CUTADAPT_MOD_VER

	echo "$0: Trimming offset nucleotides (if applicable)..."
	echo "$0: Forward offset = $FOR_OFFSET nucleotides"
	echo "$0: Reverse offset = $REV_OFFSET nucleotides"
	
	# Move input files to working directory
	mv -v trimmed_fastas/* .

	for i in *.fasta; do
		PRE_OFFSET=${i//trimmed/preoffset}
		OFFSET_TEMP=${i//trimmed/offset.temp}
		OUTPUT=${i//trimmed/offset}
		if ((FOR_OFFSET > 0)) && ((REV_OFFSET > 0)); then
			biExec cutadapt -u $FOR_OFFSET -o $OFFSET_TEMP\
				$i
			biExec cutadapt -u -$REV_OFFSET -o $OUTPUT\
				$OFFSET_TEMP
		elif ((FOR_OFFSET > 0)); then
			biExec cutadapt -u $FOR_OFFSET -o $OUTPUT\
				$i
		else
			biExec cutadapt -u -$REV_OFFSET -o $OUTPUT\
				$i
		fi
	done

	# Remove temp files
	rm -v *.temp.fasta 

	# Move input files back to corresponding directory
	mv -v *.trimmed.fasta trimmed_fastas

	# Create output directory
	mkdir offset_fastas
	mv -v *.offset.* offset_fastas
	#outStore offset_fastas "*.offset.fasta"
}

phixScreen(){
	# DESCRIPTION: Takes in a fasta file, phix databases in a directory named
	# 	$PWD/phix_db/ and screens for PhiX contamination

	# INPUT: bowtie2(), (trimmed_fastas/|offset_fastas/), $PHIX_DB
	# OUTPUT: *.screened.fasta, *.merged.PhiX, *.merged.bowtie
	# Deps: bowtie2
	
	# Set input type
	if [[ -d offset_fastas ]]; then
		IN_TYPE=offset.fasta
	else
		IN_TYPE=trimmed.fasta
	fi

	# Set input files and directories
	IN_DIR=${IN_TYPE%.fasta}\_fastas
	IN_FILE=()
	for file in $IN_DIR/*; do
		# If files in the input directory match the
		#	input type pattern, add them to the input
		#	file array
		if [[ $file =~ $IN_TYPE ]]; then
			IN_FILE+=("${file##*/}")
		fi
	done
	echo "$0: PhiX IN_DIR = $IN_DIR, IN_FILE = ${IN_FILE[@]}"

	# Move input files to working directory
	echo "\$IN_DIR/\${IN_FILE[*]} = $IN_DIR/${IN_FILE[*]}"
	mv -v $IN_DIR/${IN_FILE[*]} .

	pathTester bowtie2 $BOWTIE2_MODULE $BOWTIE2_MOD_VER
	echo "$0: Screening for PhiX contamination"

	# Set default PhiX db directory (if none provided)
	if [[ ! $PHIX_DB ]]; then
		PHIX_DB=phix_db/PhiX_bowtie_db
	fi

	# Loop bowtie2 over processed fastas
	for i in ${IN_FILE[@]}; do
		echo "TEST: -f $i -S ${i%%.*}.merged.bowtie"\
			"--un ${i%%.}.screened.fasta"
		echo "--al ${i%%.*}.merged.PhiX"\
			"--local -p $THREADS"
#		biExec bowtie2 -f $i -x $PHIX_DB\
#			-S ${i%%.*}.merged.bowtie\
#			--un ${i%%.}.screened.fasta\
#			--al ${i%%.*}.merged.PhiX\
#			--local -p $THREADS
	done

	# Once complete, generate list of reads to be screened out
	for i in *.merged.PhiX; do
		if [[ -s $i ]]; then
			echo "generating PhiX accession number file..."
			# Old grep command, probably won't work on multiple
			# 	files without generating "<filename>:<accno>"
			# grep ">" *merged.PhiX >> PhiX.accnos

			# [Do accnos in *.merged.PhiX start with ">"?]
			# 	also, this works with *.merged.PhiX,
			#	not just a single file "merged.PhiX"
			grep -Eo "[A-Z]{3,6}[0-9]+\.[0-9]+" *.merged.bowtie \
			| awk -F: '{ print $2 }' >> PhiX.accnos
		else
			echo "$0: All *.merged.PhiX are empty,"\
				"skipping PhiX.accnos generation"
		fi
	done

	# Move outputs into new directory
#	mkdir PhiX
#	phix_exts=("*.merged.PhiX" "*.merged.bowtie" "*.screened"\
#		"PhiX.accnos")
#	for i in ${phix_exts[@]}; do
#		if [[ -f $i ]]; then
#			mv -v $i PhiX
#		fi
#	done
#
#	# Return inputs to their directory
#	mv -v *.$IN_TYPE.* $IN_DIR

	# Set output files and directories
	OUT_DIR=PhiX\_fastas
	OUT_TYPE=("*.merged.PhiX" "*.merged.bowtie" "*.screened"\
		"PhiX.accnos")
	OUT_FILE=()
	for pattern in ${OUT_TYPE[*]}; do
		for file in $pattern; do
			if [[ -f $file ]]; then
				OUT_FILE+=("$file")
			fi
		done
	done
	echo "$0: PhiX OUT_DIR = $OUT_DIR, OUT_FILE = ${OUT_FILE[@]}"
	mkdir $OUT_DIR

	# Move output files to output directory
	mv -v ${OUT_FILE[*]} $OUT_DIR
}


groupConcat(){
	# Concat all specified files and save to a defined output

	# INPUT: $1
	# OUTPUT: $2

	for x in $1; do
		# Concat to fasta designated with authors name (from PWD)
		echo "$0: Adding $x to $2..."
		cat $x >> $2
	done
}


mothurScreen(){
	# Runs mothur against screening_batch.txt to screen concat'd fasta

	# INPUT: mothur(), PhiX.accnos, $AUTHOR.concat.fasta,
	#		$AUTHOR.groups
	# OUTPUT: *.good.* *.bad.*

	pathTester mothur $MOTHUR_MODULE $MOTHUR_MOD_VER
	SCREEN_FASTA=$AUTHOR.concat.fasta
	SCREEN_GROUPS=$AUTHOR.groups

	# Remove PhiX contamination
	if [[ -s PhiX/PhiX.accnos ]]; then
		echo "remove.seqs(fasta=$SCREEN_FASTA,"\
			"group=$AUTHOR.groups,"\	# Not needed by mothur?
			"accnos=PhiX.accnos)" \
			>> phix_batch.txt
		biExec mothur phix_batch.txt
		rm -v phix_batch.txt
	else
		echo "$0: PhiX.accnos is empty, skipping..."
	fi

	# Create screening_batch.txt and execute
	if [[ ! $SCREEN_FASTA ]] || [[ ! $SCREEN_GROUPS ]]; then
		echo "$0: Error! Zero-length input variables detected"
		exit 1
	else
		echo "screen.seqs(fasta=$SCREEN_FASTA, group=$SCREEN_GROUPS,"\
			"minlength=200, maxlength=300, maxambig=0, maxhomop=8)"\
			> screening_batch.txt
		echo "summary.seqs(fasta=current, processors=$THREADS)"\
			>> screening_batch.txt
		echo "count.groups(group=current)" >> screening_batch.txt
	
		echo "$0: cat'ing screening_batch.txt" 
		cat screening_batch.txt
		biExec mothur screening_batch.txt 
		rm screening_batch.txt
	fi

	# TODO: See if this condensed version of the above still works
#	if [[ ! $SCREEN_FASTA ]] || [[ ! $SCREEN_GROUPS ]]; then
#		echo "$0: Error! Zero-length input variables detected"
#		exit 1
#	else
#		SCREEN_PARAMS+=("fasta=$SCREEN_FASTA" "group=$SCREEN_GROUPS"\
#			"minlength=200" "maxlength=300" "maxambig=0"\
#			"maxhomop=8")
#		SUMMARY_PARAMS+=("fasta=current" "processors=$THREADS")
#		mothurBatch screen seqs $SCREEN_PARAMS > screening_batch.txt
#		mothurBatch summary seqs $SUMMARY_PARAMS >> screening_batch.txt
#		mothurBatch count groups "group=current" >> screening_batch.txt 
#	
#		echo "$0: cat'ing screening_batch.txt" 
#		cat screening_batch.txt
#		biExec mothur screening_batch.txt 
#		rm screening_batch.txt
#	fi
}


groupSplit(){
	# Splits the screened fasta to prepare for fasta header relabeling,
	# 	necessary for vsearch later

	pathTester mothur $MOTHUR_MODULE $MOTHUR_MOD_VER
	GOOD_FASTA=$AUTHOR.concat.fasta
	GOOD_GROUPS=$AUTHOR.groups
	echo "GOOD_FASTA=$GOOD_FASTA, GOOD_GROUPS=$GOOD_GROUPS"
	
	mothurBatch split groups "(fasta=$GOOD_FASTA, group=$GOOD_GROUPS)"\
		> split_batch.txt
	biExec mothur $BATCH_FILE
#	echo "$0: groupSplit dry run, cat'ing $BATCH_FILE"
#	cat $BATCH_FILE
	rm $BATCH_FILE

	# Rename output fastas to reasonable names
	for i in *.fasta; do
		if [[ "$i" =~ "concat.$AUTHOR" ]]; then
			# Remove everything up to "concat."
			# (i.e. result: author_year_accno.fasta)
			echo "$0: Renaming output files to"\
				"format: author_year_accno.fasta"
			mv -v $i ${i#*concat.}
		else
			continue
		fi
	done
}


fastaHeaderrelabel(){
	# Takes a fasta file labeled <author>_<year>_<accno>.fasta
	# 	and relabels headers for use with vsearch
	#
	# e.g.:
	# ">SRR10007909.1201 1201 length=251"
	# 		|
	# 		V
	# ">Li_2019_SRR10007909_1;barcodelabel=Li_2019_SRR10007909;"
		

	# INPUT:  $AUTHOR_*.fasta
	# OUTPUT: *.bar.fasta

	for i in "$AUTHOR"_*.fasta; do
		awk -v NAME_STRIPPED="${i%.fasta}" '{
			# Count every header line
			if (/^>/) COUNT+=1 

			# Define new header format
			VSEARCH_HEADER=">"NAME_STRIPPED"_"COUNT"\;barcodelabel="NAME_STRIPPED"\;"

			# Relabel everything after ">" with new header
			gsub(/^>.*/, VSEARCH_HEADER)
			print;
		}' $i > ${i%.fasta}.bar.fasta \
			# Suppress warning for "\;", that is intentional
			2>/dev/null
	done
}


garbageDay(){
	unneeded_files+=("*.bad.*" "*.trimmed.*" "*.screened.*"\
		"$AUTHOR\_*.fasta" "fastq-dump.err")
	for i in ${unneeded_files[@]}; do
		if [[ -f $i ]]; then
			rm -v $i
		fi
	done
}


# --------------------
# -- Util Functions --
# --------------------

nucRegex(){
	# Convert degenerate bases to regex patterns

	# INPUT: string
	# OUTPUT: string

	echo $1 | sed '
	s/W/(A|T)/
	s/S/(C|T)/
	s/M/(A|C)/
	s/K/(G|T)/
	s/R/(A|G)/
	s/Y/(C|T)/
	s/B/[CGT]/
	s/D/[AGT]/
	s/H/[ACT]/
	s/V/[ACG]/
	s/N/./
	s/X/./
	'
}


pathTester(){
	# Test if cutadapt is in PATH, and load if necessary
	# Usage: pathTester <executable> <module (opt.)> <version (opt.)>

	if [[ $(type -t $1) ]]; then
		echo "$0: $1 is in PATH"
		inPath=1
	elif [[ $(type -t ./$1) ]]; then
		echo "$0: WARNING: $1 is in directory, but not PATH"
		inPath=0
	elif [[ $(type -t module) ]]; then
	    	echo "$0: $1 not found in PATH"
		echo "$0: Running command: module load $2"
		module load $2/$3
	    	inPath=1
	else
		echo "$0: Error! No module, local executable, or path"\
			"executable found. Aborting..."
		exit 1
	fi
}


biExec(){
	# Use after pathTester, executes local executable if not in path
	# Usage: biExec <command string>
	if ((inPath=1)); then
		echo "\$inPath = $inPath"
		echo "$0: Using executable in path"
		echo "$0: command: $*"
		$*
	else
		echo "\$inPath = $inPath"
		echo "$0: Using local executable"
		echo "$0: command: $*"
		./$*
	fi
}


sufRegex(){
	# Takes in unmerged fastq ending in _1|_R1,
	# 	and returns suffic regex and the name
	# 	of the reverse read

	# INPUT: *1.fastq
	# OUTPUT: $REV
	# [Maybe just change incoming "_R1" to "_1" so we don't have to deal
	# 	with it in the first place]

	if [[ "$1" =~ "_1.fastq" ]]; then
		REV=${1//_1.fastq/_2.fastq}
	elif [[ "$1" =~ "_R1.fastq" ]]; then
		REV=${1//_R1.fastq/_R2.fastq}
	else
		echo "$0: Error: Expected merge suffices not found" >&2
		exit 1
	fi
}


joinBy(){
	# Description: Helper function to join arguments with a given separator

	# INPUT: $* 
	# OUTPUT: $*

	OIFS=$IFS
	IFS=$1

	shift
	echo "$*"

	IFS=$OIFS
}

inputNonzero(){
	# Checks if input variables are non-zero, otherwise calls 'exit 1'
	# 	and ends the script

	for i in $@; do
		[[ -z $i ]] && exit 1 || continue
	done
}


outStore(){
	# Creates an output directory and stores matching files in it
	# INPUT: <directory name> <file type 1> ... <file type n>
	# OUTPUT: directory/<file type {1..n}>
	# Ex: outStore PhiX "*.merged.PhiX" "*.merged.bowtie" "*.screened"

	OUT_DIR=$1
	mkdir $OUT_DIR
	for i in $@; do
		echo "adding $i to out_array"
		out_array+=("$i")
	done
	
	for i in ${out_array[@]}; do
		mv -v $i -t $OUT_DIR
	done
}


mothurBatch(){
	# Wrapper script for generating simple mothur commands, prints
	# 	command to stdout to create batch files

	# Note: If you have many parameters, put them in an array!
	# Ex: EX_PARAMS+=(fasta=blah.fasta,"\
	#	group=blah.groups)
	#
	# Just make sure to refer to them with * expansion, not @ expansion
	# e.g. mothurBatch doggo play ${EX_PARAMS[*]}
	# 	|==> doggo.play(fasta=blah.fasta, group=blah.groups)

	COMMAND="$1.$2"
	PARAMS="$3"
	BATCH_FILE=$1_$2_batch.txt

	echo "$COMMAND($PARAMS)"
}

inTypes(){
	# Takes a name of an existing directory and a regex pattern,
	#	and generates variables for input directory and file
	# Usage: inTypes <input directory> <input type>
	# INPUT: dir, regex pattern
	# OUTPUT: $IN_DIR, $IN_FILE

	# Set input files and directories
	IN_DIR=$1
	IN_TYPE=$2
	IN_FILE=()
	for file in $IN_DIR; do
		if [[ $file =~ $IN_TYPE ]]; then
			IN_FILE+=("$file")
		fi
	done
}

# =============	
# == M A I N ==
# =============

main(){
	logfile=metagen.$(date +%d_%H_%M_%S).log
	date -u > $logfile
	sraFinder

	# Download fastqs by accession number
	if [[ $SKIP_DOWNLOAD > 0 ]]; then
		echo "Skipping fastq re-download"
	else
		srrMunch 
	fi

	# Merge forward and reverse reads
	if [[ $SKIP_MERGE > 0 ]]; then
		#TODO: Clean this up so it's not in main
		echo "$0: Skipping merge stage"
		echo "$0: Renaming fastqs for pipeline compatibility"
		for i in *.fastq; do
			mv $i ${i%.fastq}.merged.fastq
		done
	else
		mergeSeqs
	fi

	q2aReformat
	groupFormatter
	trimLoop

	# Trim nucleotide offset
	if [[ $FOR_OFFSET > 0 ]] || [[ $REV_OFFSET > 0 ]]; then
		offsetTrim
	else
		echo "$0: no offset specified, make sure this"\
			"is the right target region! (In this case: 520F-802R)"
	fi

	phixScreen
#	groupConcat "PhiX/*.screened.fasta" "$AUTHOR.concat.fasta"
#	mothurScreen
	#groupSplit
	#fastaHeaderrelabel
	#groupConcat "*bar.fasta" "$AUTHOR.barcoded.fasta"

	# Remove unneeded files
#	if [[ $KEEP_FILES > 0 ]]; then
#		echo "$0: Keeping all generated files"
#	else
#		garbageDay
#	fi

	date -u >> $logfile
}

#main
phixScreen

shopt -u nullglob

# Homework:
# 
# * Modify funcs to create folders for output files
# 	(and read from folders for inputs)
#
# * Keep all: merged fastqs, fastas w/o primers, offset fastas,
# 		$AUTHOR.concat.fasta, mothur outputs, barcoded fasta
