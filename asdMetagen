#!/bin/bash
# asdMetagen -- A bash script to prepare unmerged 16S V4 fastqs for
#			metagenomic analysis. 

# AUTHOR: Sam Johnson
# LICENSE: AGPL-3.0-or-later
#	https://www.gnu.org/licenses/agpl-3.0.html
# DEPENDS: poppler-utils v0.87.0-1, bash v5.0.016-1, bbmap v38.00, mothur v1.39.5, 
# 		sratoolkit v2.10.5, cutadapt v2.8, bowtie2 v2.3.5.1
# VERSION: 0.9.0

# Set shell options (undone at end of script)
shopt -s nullglob

# Set input files
RUNTABLE=SraRunTable.txt
ACCESSION_LIST=SRR_Acc_List.txt

# Set author (from current directory)
AUTHOR=${PWD##*/}

# Set Dependency Module Versions & Names
SRA_MODULE=sratoolkit
SRA_MOD_VER=2.10.0

BBMAP_MODULE=bbmap
BBMAP_MOD_VER=38.82

CUTADAPT_MODULE=cutadapt
CUTADAPT_MOD_VER=2.0

MOTHUR_MODULE=mothur
MOTHUR_MOD_VER=1.39.5

BOWTIE2_MODULE=bowtie2
BOWTIE2_MOD_VER=2.3.4.1

# Define usage statement
usage(){
	echo "Usage: $0 -hlDMnpdctT"\
		"-f <forward primer> -r <revcomp'd reverse primer>"
	echo "	-h : help"
	echo "	-l : local mode (restricts default thread count)"
	echo "	-DM : skip 'Download fastqs' | 'Merge fastqs'"
	echo "	-n <integer> : set number of threads"
	echo "	-p <directory> : set PhiX db for bowtie2"\
		"(./PhiX_bowtie_db/phix_db by default)"
	echo "	-d \"<delimiter>\" : set custom delimiter for run table (Note the double quotes!)"
	echo "	-c <integer> : set column number for run table accnos"
	echo "	-t <integer> : set offset on 5' end (in nucleotides)"
	echo "	-T <integer> : set offset on 3' end"
	echo "	NOTE: Ommitting forward or reverse primer will cancel"
	echo "	primer trimming on that end of the read."
	echo "		Ex: '$0 -r <primer>' will only trim the 3' primer" 
}

# Define use flags
while getopts "hlDMn:p:d:c:t:T:f:r:" FLAGS; do
	case "${FLAGS}" in
		h)
			usage
			exit 0
			;;
		l)
			LOCAL=1
			;;
		D)
			SKIP_DOWNLOAD=1
			;;
		M)
			SKIP_MERGE=1
			;;
		n)
			THREADS=$OPTARG
			echo "THREADS = $THREADS"
			;;
		p)
			PHIX_DB=$OPTARG
			echo "PHIX_DB = $PHIX_DB"
			;;
		d)
			DELIMITER=$OPTARG
			echo -e "DELIMITER = $DELIMITER"
			;;
		c)
			COLUMN=$OPTARG
			echo "Run Table accession number column: $COLUMN"
			;;
		t)
			FOR_OFFSET=$OPTARG
			echo "FOR_OFFSET = $FOR_OFFSET"
			;;
		T)
			REV_OFFSET=$OPTARG
			echo "REV_OFFSET = $REV_OFFSET"
			;;
		f)
			FORPRIME=$OPTARG
			echo "FORPRIME = $FORPRIME"
			;;
		r)
			REVPRIME=$OPTARG
			echo "REVPRIME = $REVPRIME"
			;;
		esac
done

# Set available threads 
if [[ $LOCAL ]]; then
	THREAD_DEFAULT=$(( $(nproc) - 2 ))
else
	THREAD_DEFAULT=$(nproc)
fi

if [[ ! $THREADS ]]; then
	echo "$0: Setting threads to default setting"
	THREADS=$THREAD_DEFAULT
fi
echo "$0: THREADS = $THREADS"

# ====================
# == MAIN Functions ==
# ====================


srrMunch(){
	# Short script to loop through SRRs in an SRA list, running fastq-dump, and
	# 	nicely formatting them with bbtools' reformat.sh (for now, with manual
	#	read number relabeling).

	# Deps: fastq-dump from NCBI SRA Toolkit

	# Check Run Table first for a list of 16S seqs
	[[ $COLUMN ]] || COLUMN=1
	if [[ $DELIMITER ]]; then
		echo "$0: Running command:"
		echo -e "awk -F $DELIMITER -v c=$COLUMN '/16S/ { print $c }'"\
			"$RUNTABLE > 16S_list.txt.temp"
		awk -F $DELIMITER -v c=$COLUMN '/16S/ { print $c }' $RUNTABLE\
			> 16S_list.txt.temp
	else
		echo "$0: Running command:"
		echo "awk -v c=$COLUMN '/16S/ { print $c }'"\
			"$RUNTABLE > 16S_list.txt.temp"
		awk -v c=$COLUMN '/16S/ { print $c }' $RUNTABLE\
			> 16S_list.txt.temp
	fi

	# Set which list to loop fastq-dump over
	if [[ -s 16S_list.txt.temp ]]; then
		READ_LIST=16S_list.txt.temp	
	else
		echo "$0: awk filter failed to find 16S seqs,"\
			"leaving filtering duties to cutadapt.."
		READ_LIST=$ACCESSION_LIST
	fi

	echo "$0: Looping through $READ_LIST with sratoolkit and" \
		"unpacking fastqs..."

	# Loop fastq-dump over Accession Number list
	pathTester fastq-dump $SRA_MODULE $SRA_MOD_VER
	while read accno; do
		fastq-dump --split-3 --gzip $accno 2>>fastq-dump.err
		gzip -d $accno*.fastq.gz
	done <$READ_LIST
	[[ ! -f 16S_list.txt.temp ]] || rm -v 16S_list.txt.temp

	# TODO: Parameterize fastq-dump call?
	# Parse fastq-dump.err files for fastq-dump download errors, 
	# store matching accession numbers in array
	fastq_err=()
	while IFS= read -r -d $'\0' line; do
		fastq_err+=("$line")
	done < <(awk '/fastq-dump.*err:/ { print $NF }' fastq-dump.err)

	# If fastq-dump error accnos are found, delete the messed up fastqs
	# 	re-download, and re-decompress them
	if [[ ${#fastq_err[@]} > 0 ]]; then
		for i in ${fastq_err[*]}; do
			rm $i*.fastq
			fastq-dump --split-3 --gzip $i
			gzip -d $accno*.fastq.gz
		done
	else
		echo "$0: No download errors found for fastq-dump" 
		rm -v fastq-dump.err
	fi

	# Create output directory
	mkdir fastqs
	mv -v *.fastq fastqs
}


16sExtractor(){
	# Description: takes an SraRunTable file from NCBI and outputs all
	# 		SRR's that contain "16S"

	# INPUT: fastq-dump, $RUNTABLE, *.fastq
	# OUTPUT: filter/, *.fastq

	# Set input type
	in_type=X

	# Move input files to working directory
	inPrep Y

	echo "$0: Filtering out non-16S fastqs by runtable metadata..."

	
	mkdir 16S_temp filter
	if [[ $COLUMN ]]; then
		awk -v c=$COLUMN '/16S/ { print $c }' $RUNTABLE \
			> 16S_list.txt.temp
	else
		awk '/16S/ { print $1 }' $RUNTABLE \
			> 16S_list.txt.temp
	fi
	if [[ -s 16S_list.txt.temp ]]; then
		# Create list of 16S seqs from the runtable
		while read line; do
			#echo "$line.fastq"
			eval mv -v fastqs/$line*.fastq 16S_temp # Move 16S seqs to temp dir
		done < 16S_list.txt.temp
		# Move the non-match seqs to the filter, or remove filter if all seqs match
		filter_array=()
		while IFS= read -r -d $'\0' line; do
			filter_array+=("$line")
		done < <(find fastqs -maxdepth 1 -name "*.fastq" -print0)
		if [[ ${#filter_array[@]} > 0 ]]; then
			# move any remaining fastqs to filter
			mv -v fastqs/* filter
		else
			# ...or delete filter/ if there aren't any left
			rmdir filter
		fi
	else
		echo "$0: awk filter failed to find 16S seqs,"\
			"leaving filtering duties to cutadapt.."
	fi

	rm -v 16S_list.txt.temp
	#mv -v 16S_temp/* fastqs && rmdir 16S_temp

	# Move inputs and outputs back to corresponding directories
	out_type=X
	outPrep Y Z
}


mergeSeqs(){
	# DESCRIPTION: A simple script that runs bbmerge.sh to merge all fastqs in the current
	# 	directory.

	# INPUT: sufRegex(), bbmerge.sh(), fastqs/
	# OUTPUT: merged_fastqs/

	# Deps: bbmerge.sh

	# Set input type
	in_type=fastq

	# Move input files to working directory
	inPrep fastqs

	pathTester bbmerge.sh $BBMAP_MODULE $BBMAP_MOD_VER

	echo "$0: Checking forward and reverse fastq read counts"\
		"prior to merging"

	# Merge all _1 & _2 fastqs
	for i in ${in_file[@]}; do
		if [[ $i =~ _1.fastq ]]; then
			# Select forward reads in the for loop,
			#	then designate the reverse from $i
			REV=${i//_1.fastq/_2.fastq}
			READ_NAME=${i%_1.fastq}
			OUT_FILE=${i%_1.fastq}.merged.fastq
			# Make sure the read numbers are identical between
			#	forward and reverse
			echo "Checking: $i $REV"
			F_READ_NUM=$(grep -c "@$READ_NAME" $i)
			R_READ_NUM=$(grep -c "@$READ_NAME" $REV)
	
			if [[ $F_READ_NUM == $R_READ_NUM ]]; then
				echo "$0: Read counts match; "\
					"Now merging: $i and $REV"
				echo "$0: Merge out file: $OUT_FILE"
				bbmerge.sh in1="$i" in2="$REV" out="$OUT_FILE"
			else
				echo "Mismatch found, delete reads for $READ_NAME and "\
					"re-run fastq-dump before proceeding"
				exit 0
			fi
		fi
	done
	
	# Move inputs and outputs back to corresponding directories
	out_type="merged.fastq"
	outPrep fastqs merged_fastqs
}


q2aReformat(){
	# DESCRIPTION: Reformats all fastq files in current directory to fasta

	# Deps: bbtools 'reformat' tool

	# Set input type
	in_type=fastq

	# Move input files to working directory
	inPrep merged_fastqs

	pathTester reformat.sh $BBMAP_MODULE $BBMAP_MOD_VER

	echo "$0: Reformatting merged fastqs files to fasta format..."
	for i in ${in_file[@]}; do
		reformat.sh in=$i out=${i%.fastq}.fasta
	done

	# Move inputs and outputs back to corresponding directories
	out_type=fasta
	outPrep merged_fastqs merged_fastas
}


groupFormatter(){
	# Description: Scans current directory for .fasta files, and
	#              formats them for use with the R package Mothur's
	#              'make.group()' command

	# Set input type
	in_type=fasta

	# Move input files to working directory
	inPrep merged_fastas

	# Load executable if necessary
	pathTester mothur $MOTHUR_MODULE $MOTHUR_MOD_VER

	# Create hyphen-delimited lists for fastas and groups
	formatter_fastas=$(joinBy - ${in_file[*]})
	for i in ${in_file[@]}; do
		group_array+=("$AUTHOR"_"${i%%.*}")
	done
	formatter_groups=$(joinBy - ${group_array[*]})

	# Set mothur command parameters and run mothur
	group_params=("fasta=$formatter_fastas," "groups=$formatter_groups,"\
		"output=$AUTHOR.groups")
	mothur <(mothurBatch make group "${group_params[*]}")

	# Move inputs and outputs back to corresponding directories
	out_type=$AUTHOR.groups
	outPrep merged_fastas .
}


trimLoop(){
	# Takes the primer patterns from command line,
	# inputs to cutadapt, and loops through all fasta # files in $(pwd)

	# INPUT: cutadapt(), $FORPRIME, $REVPRIME, *.merged.fasta
	# OUTPUT: *.trimmed.fasta
	
	# Set input type
	in_type=fasta

	# Move input files to working directory
	inPrep merged_fastas
	pathTester cutadapt $CUTADAPT_MODULE $CUTADAPT_MOD_VER

	echo "$0: Trimming primers..."
	echo "$0: FORPRIME = $FORPRIME \t REVPRIME = $REVPRIME"

	for i in ${in_file[@]}; do
		m=${i%.fasta}
		if [[ $FORPRIME ]]; then
			echo "$0: FORPRIME = $FORPRIME"
			cutadapt -g $FORPRIME\
				-o $m.temp.fasta $i\
				--discard-untrimmed
		fi

		if [[ $REVPRIME ]]; then
			echo "$0: REVPRIME = $REVPRIME"
			cutadapt -a $REVPRIME\
				-o $m.trimmed.fasta $m.temp.fasta\
				--discard-untrimmed
		fi
	done
	rm -v *.temp.fasta
	
	# Move inputs and outputs back to corresponding directories
	out_type=trimmed.fasta
	outPrep merged_fastas trimmed_fastas
}


offsetTrim(){
	# Apply offset (if applicable)
	# 
	pathTester cutadapt $CUTADAPT_MODULE $CUTADAPT_MOD_VER

	# Set input type
	in_type=fasta

	# Move input files to working directory
	inPrep trimmed_fastas

	for i in ${in_file[@]}; do
		PRE_OFFSET=${i//trimmed/preoffset}
		OFFSET_TEMP=${i//trimmed/offset.temp}
		OUTPUT=${i//trimmed/offset}
		if [[ $FOR_OFFSET ]] && [[ $REV_OFFSET ]]; then
			echo "$0: Trimming $FOR_OFFSET nucleotides"\
				"from 5' end of $i"
			cutadapt -u $FOR_OFFSET -o $OFFSET_TEMP $i

			echo "$0: Trimming $REV_OFFSET nucleotides"\
				"from 3' of $OFFSET_TEMP"
			cutadapt -u -$REV_OFFSET -o $OUTPUT $OFFSET_TEMP
		elif [[ $FOR_OFFSET ]]; then
			echo "$0: Trimming $FOR_OFFSET nucleotides"\
				"from 5' end of $i"
			cutadapt -u $FOR_OFFSET -o $OUTPUT $i
		else
			echo "$0: Trimming $REV_OFFSET nucleotides"\
				"from 3' of $i"
			cutadapt -u -$REV_OFFSET -o $OUTPUT $i
		fi
	done

	# Remove temp files
	rm -v *.temp.fasta 

	# Move inputs and outputs back to corresponding directories
	out_type=offset
	outPrep trimmed_fastas offset_fastas
}

phixScreen(){
	# DESCRIPTION: Takes in a fasta file, phix databases in a directory named
	# 	$PWD/phix_db/ and screens for PhiX contamination

	# INPUT: bowtie2(), (trimmed_fastas/|offset_fastas/), $PHIX_DB
	# OUTPUT: *.screened.fasta, *.merged.PhiX, *.merged.bowtie
	# Deps: bowtie2
	
	# Set input type
	if [[ -d offset_fastas ]]; then
		in_type=offset.fasta
	else
		in_type=trimmed.fasta
	fi

	# Set input files and directories
	inPrep ${in_type%.fasta}\_fastas

	pathTester bowtie2 $BOWTIE2_MODULE $BOWTIE2_MOD_VER

	# Set default PhiX db directory (if none provided)
	if [[ ! $PHIX_DB ]]; then
		PHIX_DB=phix_db/PhiX_bowtie_db
	fi

	# Loop bowtie2 over processed fastas
	echo "$0: Screening for PhiX contamination"
	for i in ${in_file[@]}; do
		bowtie2 -f $i -x $PHIX_DB\
			-S ${i%%.*}.merged.bowtie\
			--un ${i%%.*}.screened.fasta\
			--al ${i%%.*}.merged.PhiX\
			--local -p $THREADS
	done

	# Once complete, generate list of reads to be screened out
	for i in *.merged.PhiX; do
		if [[ -s $i ]]; then
			echo "generating PhiX accession number file..."
			# Old grep command, probably won't work on multiple
			# 	files without generating "<filename>:<accno>"
			# grep ">" *merged.PhiX >> PhiX.accnos

			# [Do accnos in *.merged.PhiX start with ">"?]
			# 	also, this works with *.merged.PhiX,
			#	not just a single file "merged.PhiX"
			grep -Eo "[A-Z]{3,6}[0-9]+\.[0-9]+" *.merged.bowtie \
			| awk -F: '{ print $2 }' >> PhiX.accnos
		else
			rm $i
		fi
	done

	# Concatenate PhiX screened fastas to single file
	# (identified by $AUTHOR)
	groupConcat "*.screened.fasta" $AUTHOR.concat.fasta

	# Create output folder for screened fastas (separate from other PhiX outputs)
	mkdir screened_fastas && mv *.screened.fasta screened_fastas

	# Remove unneeded ".bowtie" outs
	rm *.merged.bowtie

	# Move inputs and outputs back to corresponding directories
	out_type=("merged.PhiX" "merged.bowtie" "PhiX.accnos")
	outPrep ${in_type%.fasta}\_fastas PhiX_outs
}


mothurScreen(){
	# Runs mothur against screening_batch.txt to screen concat'd fasta

	# INPUT: mothur(), PhiX.accnos, $AUTHOR.concat.fasta,
	#		$AUTHOR.groups
	# OUTPUT: *.good.* *.bad.*

	pathTester mothur $MOTHUR_MODULE $MOTHUR_MOD_VER
	screen_fasta=$AUTHOR.concat.fasta
	screen_groups=$AUTHOR.groups

	# Remove PhiX contamination
	if [[ -s PhiX_outs/PhiX.accnos ]]; then
		remove_params=("fasta=$screen_fasta,"\
			"group=$screen_groups,"\	# Not needed by mothur?
			"accnos=PhiX/PhiX.accnos")
		mothur <(mothurBatch remove seqs "${remove_params[*]}")
		rm -v phix_batch.txt
	else
		echo "$0: PhiX.accnos is empty, skipping..."
	fi

	# Create screening_batch.txt and execute
#	if [[ ! $screen_fasta ]] || [[ ! $screen_groups ]]; then
#		echo "$0: Error! Zero-length input variables detected"
#		exit 1
#	else
#		echo "screen.seqs(fasta=$screen_fasta, group=$screen_groups,"\
#			"minlength=200, maxlength=300, maxambig=0, maxhomop=8)"\
#			> screening_batch.txt
#		echo "summary.seqs(fasta=current, processors=$THREADS)"\
#			>> screening_batch.txt
#		echo "count.groups(group=current)" >> screening_batch.txt
#	
#		echo "$0: cat'ing screening_batch.txt" 
#		cat screening_batch.txt
#		mothur screening_batch.txt 
#		rm screening_batch.txt
#	fi

	# TODO: See if this condensed version of the above still works
	if [[ ! $screen_fasta ]] || [[ ! $screen_groups ]]; then
		echo "$0: Error! Zero-length input variables detected"
		exit 1
	else
		screen_params=("fasta=$screen_fasta," "group=$screen_groups,"\
			"minlength=200," "maxlength=300," "maxambig=0,"\
			"maxhomop=8")
		summary_params=("fasta=current," "processors=$THREADS")
		mothurBatch screen seqs "${screen_params[*]}" > screening_batch.txt
		mothurBatch summary seqs "${summary_params[*]}" >> screening_batch.txt
		mothurBatch count groups "group=current" >> screening_batch.txt 
	
		echo "$0: cat'ing screening_batch.txt" 
		cat screening_batch.txt
		mothur screening_batch.txt 
		rm screening_batch.txt
	fi

	out_type=(".bad" ".good")
	outPrep PhiX_fastas .
}


groupSplit(){
	# Splits the screened fasta to prepare for fasta header relabeling,
	# 	necessary for vsearch later

	in_type=good.fasta
	inPrep .

	pathTester mothur $MOTHUR_MODULE $MOTHUR_MOD_VER
	for i in *.fasta; do
		if [[ $i =~ good ]]; then
			GOOD_FASTA=$i
		fi
	done; 
#	GOOD_FASTA=$AUTHOR.concat.fasta
	for i in *.groups; do
		if [[ $i =~ good ]]; then
			GOOD_GROUPS=$i
		fi
	done
#	GOOD_GROUPS=$AUTHOR.groups
	
	echo "GOOD_FASTA=$GOOD_FASTA, GOOD_GROUPS=$GOOD_GROUPS"
	
	split_params=("fasta=$GOOD_FASTA,"\
		"group=$GOOD_GROUPS")
	mothur <(mothurBatch split groups "${split_params[*]}")

	# Rename output fastas to reasonable names
	for i in *.fasta; do
		if [[ $i =~ ".$AUTHOR" ]]; then
			# Remove everything up to "concat."
			# (i.e. result: author_year_accno.fasta)
			echo "$0: Renaming output files to"\
				"format: author_year_accno.fasta"
			mv -v $i ${i#*good.}
		fi
	done

	out_type=$AUTHOR\_
	outPrep . split_fastas
}


fastaHeaderrelabel(){
	# Takes a fasta file labeled <author>_<year>_<accno>.fasta
	# 	and relabels headers for use with vsearch
	#
	# e.g.:
	# ">SRR10007909.1201 1201 length=251"
	# 		|
	# 		V
	# ">Li_2019_SRR10007909_1;barcodelabel=Li_2019_SRR10007909;"
		

	# INPUT:  $AUTHOR_*.fasta
	# OUTPUT: *.barcoded.fasta

	in_type=fasta
	inPrep split_fastas

	for i in ${in_file[@]}; do
		awk -v NAME_STRIPPED="${i%.fasta}" '{
			# Count every header line
			if (/^>/) COUNT+=1 

			# Define new header format
			VSEARCH_HEADER=">"NAME_STRIPPED"_"COUNT"\;barcodelabel="NAME_STRIPPED"\;"

			# Relabel everything after ">" with new header
			gsub(/^>.*/, VSEARCH_HEADER)
			print;
		}' $i > ${i%.fasta}.bar.fasta 2>/dev/null
	done

	# Concatenate output files to single barcoded fasta
	# (also identified by $AUTHOR)
	groupConcat "*bar.fasta" $AUTHOR.barcoded.fasta

	out_type=bar.fasta
	outPrep split_fastas relabeled_fastas
}


garbageDay(){
	# Delete unneeded outputs and directories to clean up final output

	rm $AUTHOR.*.bad.*

	# Remove PhiX_outs entirely, if it's empty
	# (equivalent to "rmdir PhiX_outs" without unnecessary errors)
	find PhiX_outs -maxdepth 0 -empty -exec rmdir {} \;
}

# --------------------
# -- Util Functions --
# --------------------

nucRegex(){
	# Convert degenerate bases to regex patterns

	# INPUT: string
	# OUTPUT: string

	echo $1 | sed '
	s/W/(A|T)/
	s/S/(C|T)/
	s/M/(A|C)/
	s/K/(G|T)/
	s/R/(A|G)/
	s/Y/(C|T)/
	s/B/[CGT]/
	s/D/[AGT]/
	s/H/[ACT]/
	s/V/[ACG]/
	s/N/./
	s/X/./
	'
}


pathTester(){
	# Test if cutadapt is in PATH, and load if necessary
	# Usage: pathTester <executable> <module (opt.)> <version (opt.)>

	if [[ $(type -t $1) ]]; then
		echo "$0: $1 is in PATH"
	elif [[ $(type -t ./$1) ]]; then
		echo "$0: Error: $1 is in directory, but not PATH"
		echo "$0: Exiting..."
		exit 1
	elif [[ $(type -t module) ]]; then
	    	echo "$0: $1 not found in PATH"
		echo "$0: Command: module load $2/$3"
		module load $2/$3
	else
		echo "$0: Error: No module, local executable, or path"\
			"executable found. Aborting..."
		exit 1
	fi
}


sufRegex(){
	# Takes in unmerged fastq ending in _1|_R1,
	# 	and returns suffic regex and the name
	# 	of the reverse read

	# INPUT: *1.fastq
	# OUTPUT: $REV
	# [Maybe just change incoming "_R1" to "_1" so we don't have to deal
	# 	with it in the first place]

	if [[ "$1" =~ "_1.fastq" ]]; then
		REV=${1//_1.fastq/_2.fastq}
	elif [[ "$1" =~ "_R1.fastq" ]]; then
		REV=${1//_R1.fastq/_R2.fastq}
	else
		echo "$0: Error: Expected merge suffices not found" >&2
		exit 1
	fi
}


joinBy(){
	# Takes first argument as new delimiter, then echoes all following
	# 	arguments with that delimiter
	# Usage: joinBy <separator> <arg1> [...] <argN>

	OIFS=$IFS
	IFS=$1

	shift
	echo "$*"

	IFS=$OIF
}


groupConcat(){
	# Concat all specified files and save to a defined output

	# INPUT: $1
	# OUTPUT: $2

	for x in $1; do
		# Concat to fasta designated with authors name (from PWD)
		echo "$0: Adding $x to $2..."
		cat $x >> $2
	done
}


mothurBatch(){
	# Wrapper script for generating simple mothur commands, prints
	# 	command to stdout to create batch files

	# Note: If you have many parameters, put them in an array!
	# Ex: EX_PARAMS+=("fasta=blah.fasta,"\
	#	"group=blah.groups")
	#
	# Just make sure to refer to them with * expansion, not @ expansion,
	#	and enclose in double quotes!
	# e.g. mothurBatch doggo play "${EX_PARAMS[*]}"
	# 	|==> doggo.play(fasta=blah.fasta, group=blah.groups)

	COMMAND=$1.$2
	PARAMS="$3"
	echo "$COMMAND($PARAMS)"
}

inPrep(){
	# Takes input directory argument and global input array, and
	#	moves relevant input files to working directory
	# Usage: inPrep <IN_DIR>
	
	# Set types and directories
	IN_DIR=$1

	# Set input files
	for file in $IN_DIR/*; do
		# If files in the input directory match the
		#	input type pattern, add them to the input
		#	file array
		for i in ${in_type[*]}; do
			if [[ -f $file ]] && [[ $file =~ $i ]]; then
				echo "$0: ${file##*/} matches input type $i;"\
					"adding to input file list"
				in_file+=("${file##*/}")
				break
			fi
		done
	done

	# Exit if input file array is still empty
	if [[ ${#in_file[@]} == 0 ]]; then
		echo "$0: ERROR"
		echo "$0: No files found in input directory: $IN_DIR,"\
			"or none matching input type: $in_type"
		echo "$0: Exiting"
		exit 1
	fi

	# Move input files to working directory
	for i in ${in_file[@]}; do
		mv -v $IN_DIR/$i .
	done
}


outPrep(){
	# Moves input and output files to corresponding directories
	#	(also creates the output directory)
	# Usage: outPrep <input dir> <output dir>
 
	# Set input and output directories 
	IN_DIR=$1
	OUT_DIR=$2
	
	# Create output directory
	if [[ ! -d $OUT_DIR ]]; then
		mkdir $OUT_DIR
	fi

	# Add all files matching the output types to the output file array
	for file in *; do
		# If files in the working directory match the
		#	output type pattern, add them to the output
		#	file array
		for i in ${out_type[@]}; do
			if [[ -f $file ]] && [[ $file =~ $i ]]; then
				echo "$0: $file matches output type $i;"\
					"adding to output file list"
				out_file+=("$file")
				break
			fi
		done
	done

	# Move outputs to corresponding directories
	if [[ ${#out_file[@]} != 0 ]]; then
		mv -v ${out_file[*]} $OUT_DIR
	else
		# Print warning if output file array is still empty
		echo "$0: Warning: No files matching output types: ${out_type[@]}"
	fi

	# Move input files back to corresponding directories
	mv -v ${in_file[*]} $IN_DIR


	
	# Reset input and output arrays
	unset in_file out_file in_type out_type
}

# =============	
# == M A I N ==
# =============

main(){
	logfile=metagen.$(date +%d_%H_%M_%S).log
	date -u > $logfile

	# Download fastqs by accession number
	if [[ $SKIP_DOWNLOAD ]]; then
		echo "Skipping fastq re-download"
	else
		srrMunch 
	fi

	# Merge forward and reverse reads
	if [[ $SKIP_MERGE ]]; then
		#TODO: Clean this up so it's not in main
		echo "$0: Skipping merge stage"
		echo "$0: Renaming fastqs for pipeline compatibility"
		for i in *.fastq; do
			mv $i ${i%.fastq}.merged.fastq
		done
	else
		mergeSeqs
	fi

	q2aReformat
	groupFormatter
	trimLoop

	# Trim nucleotide offset
	if [[ $FOR_OFFSET ]] || [[ $REV_OFFSET ]]; then
		offsetTrim
	else
		echo "$0: no offset specified, make sure this"\
			"is the right target region! (In this case: 520F-802R)"
	fi

	phixScreen
	mothurScreen
	groupSplit
	fastaHeaderrelabel
	garbageDay
	date -u >> $logfile
}

main

shopt -u nullglob
