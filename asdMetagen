#!/bin/bash
# asdMetagen -- A bash script to prepare unmerged 16S V4 fastqs for
#			metagenomic analysis. 

# AUTHOR: Sam Johnson
# LICENSE: GNU Affero General Public License 
#	https://www.gnu.org/licenses/agpl-3.0.html
# DEPENDS: poppler-utils v0.87.0-1, bash v5.0.016-1, bbmap v38.00, mothur v1.39.5, 
# 		sratoolkit v2.10.5, cutadapt v2.8
# VERSION: 0.9.0

# Set input files
RUNTABLE=SraRunTable.txt
ACCESSION_LIST=SRR_Acc_List.txt

# Set primers
FORPRIME=$1
REVPRIME=$2

# Set author (from current directory)
AUTHOR=${PWD##*/}

# Set available threads (default: uses all but 2 available threads)
THREADS=${3:-$(( $(nproc) - 2 ))}

# Set Taxonomic database directory
TAXO_DB="../../databases/silva_v128/"


# Define use flags
while getopts "h" FLAGS; do
	case $FLAGS in
		h)
			echo "Usage: asdMetagen \[ forward primer \]"\
				"\[ reverse-compliment of reverse primer \]"
			exit;;
	esac
done

# Initialize arrays
	fasta_array=()
	group_array=()
	

# ====================
# == Util Functions ==
# ====================

nucRegex(){
	# Convert degenerate bases to regex patterns

	# INPUTS: string
	# OUTPUTS: string

	echo $1 | sed '
	s/W/(A|T)/
	s/S/(C|T)/
	s/M/(A|C)/
	s/K/(G|T)/
	s/R/(A|G)/
	s/Y/(C|T)/
	s/B/[CGT]/
	s/D/[AGT]/
	s/H/[ACT]/
	s/V/[ACG]/
	s/N/./
	s/X/./
	'
}


pathTester(){
	# Test if cutadapt is in PATH, and load if necessary

	if [[ -n $(type -p $2) ]]; then
		echo "asdMetagen: $2 is in PATH"
	elif [[ -n $(type -p ./$2) ]]; then
		echo "asdMetagen: WARNING: $2 is in directory, but not PATH"
	else
	    	echo "asdMetagen: $2 not found in PATH, "\
		    "if on remote, issue command: 'module avail $1', and "\
		    "load the necessary module"
#		MODULE_TO_LOAD=$(module avail $1 | awk 'END { print $NF }')
#		echo "asdMetagen: Testing command: module load $MODULE_TO_LOAD"
#		module load "$MODULE_TO_LOAD"
	    exit 1
	fi
}


sufRegex(){
	# Takes in unmerged fastq ending in _1|_R1,
	# 	and returns suffic regex and the name
	# 	of the reverse read

	# INPUTS: *1.fastq
	# OUTPUTS: $REV
	# [Maybe just change incoming "_R1" to "_1" so we don't have to deal
	# 	with it in the first place]

	if [[ "$1" =~ "_1.fastq" ]]; then
		REV=${1//_1.fastq/_2.fastq}
	elif [[ "$1" =~ "_R1.fastq" ]]; then
		REV=${1//_R1.fastq/_R2.fastq}
	else
		echo "asdMetagen: Error: Expected merge suffices not found" >&2
		exit 1
	fi
}


joinBy(){
	# Description: Helper function to join arguments with a given separator

	# INPUTS: $* 
	# OUTPUTS: $*

	OIFS=$IFS
	IFS=$1

	shift
	echo "$*"

	IFS=$OIFS
}

# ====================
# == MAIN Functions ==
# ====================

sraFinder(){
	# Simple grep parser for all NCBI SRA accession numbers in pdf files in the working directory
	# usage: <sraFinder.sh>

	if [ ! -f "SRR_Acc_List.txt" ] && [ ! -f "SraRunTable.txt" ]; then
		shopt -s nullglob
		for f in *.pdf; do
			pdftotext $f # convert pdf files to parsable txt files
			r=${f%.pdf}.txt
			PATTERN="[A-Z]{3,}[[:digit:]]{5,}"
			if [[ -n $(grep -Eo "$PATTERN" $r) ]]; then
				grep -Eo "[A-Z]{3,}[[:digit:]]{5,}" $r \
					> ${r%.txt}.sra
				# echo anything in txt that has =>3 capitals, 
				#	followed by => 5 numbers, into a new 
				#	file with a ".sra" extension (regex: 
				#	[A-Z]{3,}[[:digit:]]{5,} )
			else
				echo "No valid accession number found"\
					"in file: $f"
			fi
	
			# Make primers file for screening [WORK IN PROGRESS]
			#grep -i -P -A 1 "[0-9]{3}f" \
			#	> $(basename -- $f .pdf)_primers.txt
			#grep -i -P -A 1 "[0-9]{3}r" \
			#	>> $(basename -- $f .pdf)_primers.txt
			rm $r
		done
	
		shopt -u nullglob
	else
		echo "asdMetagen: Accession List and Run Table found,"\
			"continuing..."
fi

}

# TO DO

# Perform web search (maybe with curl, lynx?) for SRA/PRJNA/etc number,
# 	bypass writing to a separate file, and autodownload SRA
#	accession list, etc.
#
# 	https://www.ncbi.nlm.nih.gov/sra/?term=<SRA NUMBER HERE>
#
# 	Must grab from run selector! e.g. for https://www.ncbi.nlm.nih.gov/bioproject/PRJNA561262
# 	Dang it, I can't find anything for the specific buttons for RunTableInfo and Accession List;
#	I don't know enough javascript to figure out how to connect to what those buttons do. Maybe
# 	NCBI has a CLI for grabbing this stuff?
#	Oh, it'd be a good idea to confirm the SRAs etc. grabbed from each paper before grabbing those
#	docs. So it'd have to be interactive....maybe this would be a good project to learn some
#	GUI skills for...


srrMunch(){
	# Short script to loop through SRRs in an SRA list, running fastq-dump, and
	# 	nicely formatting them with bbtools' reformat.sh (for now, with manual
	#	read number relabeling).

	# INPUTS: fastq-dump(), $ACCESSION_LIST
	# OUTPUTS: *.fastq

	echo "asdMetagen: Looping through $ACCESSION_LIST with sratoolkit and" \
		"unpacking fastqs..."

	shopt -s nullglob

	SRATOOLKIT_VERSION=$(fastq-dump -V | awk '/[0-9]/ { print $3 }')

	if [[ "$SRATOOLKIT_VERSION" =~ "2.10" ]]; then
		SPLIT_OPT="--split-e"
	else
		echo "asdMetagen: toolkit ver $SRATOOLKIT_VERSION"
		SPLIT_OPT="--split-3"
		echo "asdMetagen: attempting fastq-dump with "\
			"$SPLIT_OPT option..."
	fi

	while read x; do
		if [ -f "$x.fastq.gz" ]; then
			# in case the download glitches and needs to be re-run
			continue
		else
      			fastq-dump $SPLIT_OPT --gzip $x
			gzip -d *.fastq.gz
			rm $x.fastq
		fi
	done < $ACCESSION_LIST

	shopt -u nullglob
}


16sExtractor(){
	# Description: takes an SraRunTable file from NCBI and outputs all
	# 		SRR's that contain "16S"

	# INPUTS: fastq-dump, $RUNTABLE, *.fastq
	# OUTPUTS: filter/, *.fastq

	echo "asdMetagen: Filtering out non-16S fastqs by runtable metadata..."

	mkdir 16S_temp filter
	if [ -f $RUNTABLE ]; then
		# Create list of 16S seqs from the runtable
		awk -F "," '/16S/ { print $1 }' $RUNTABLE > 16S_list.txt.temp
		while read line; do
			#echo "$line.fastq"
			eval mv $line*.fastq 16S_temp # Move 16S seqs to temp dir
		done < 16S_list.txt.temp
		rm 16S_list.txt.temp
		# Move the non-match seqs to the filter, or remove filter if all seqs match
		[[ -z $(ls | grep "\.fastq") ]] && rmdir filter || mv *.fastq filter
		mv 16S_temp/* . && rmdir 16S_temp
	else
		echo "No SraRunTable.txt found! Try grep -B 1 -E \"<FORWARD PRIMER>\" on fastqs"
		echo "\nExample output:"
		grep -EB 1 $(nucRegex $FORPRIME)
		# Put grep tool for generating 16S list here
		# 	(Note: Add both "FPRIMER" __and__ "^FPRIMER" versions, and separate
		# 	their results in different directories)
	#	        head -n 2 *.fastq \
	#	        | grep -EB 1 $FPRIMER \
	#	        | grep -o "SRR[0-9]\+" \
	#	        | sed 's/$/.fastq/'
	        echo "Error: No fastq files found in current directory"
	fi
}


mergeSeqs(){
	# DESCRIPTION: A simple script that runs bbmerge.sh to merge all fastqs in the current
	# 	directory.

	# INPUTS: sufRegex(), bbmerge.sh(), *1.fastq
	# OUTPUTS: *.merged.fastq, merged.*

	# Deps: bbmerge.sh
	# NOTE: RUN AFTER: --- srr_munch.sh
	#	RUN BEFORE: -- q2a_reformat.sh

	shopt -s nullglob

	echo "asdMetagen: Checking forward and reverse fastq read counts "\
		"prior to merging"

	# Merge all _1 & _2 fastqs
	for i in *1.fastq; do
		sufRegex $i		
		READ_NAME=$(basename $i _1.fastq) # genericize to _1 or _R1 later?
		OUT_FILE=$(echo "$i" | sed 's/_\(\|R\)1\.fastq/.merged.fastq/')

		# Make sure the read numbers are identical between forward
		# 	and reverse
		# [Clean this up, just check the first few times for efficiency]
		echo "Checking: $i $REV"
		F_READ_NUM=$(grep -c "@$READ_NAME" $i)
		R_READ_NUM=$(grep -c "@$READ_NAME" $REV)

		if [[ "$F_READ_NUM" == "$R_READ_NUM" ]]; then
			echo "asdMetagen: Read counts match; "\
				"Now merging: $i and $REV"
			echo "asdMetagen: Merge out file: $OUT_FILE"
			bbmerge.sh in1="$i" in2="$REV" out="$OUT_FILE"
		else
			echo "Mismatch found, delete reads for $READ_NAME and "\
				"re-run fastq-dump before proceeding"
			# rm $i $REV && srrMunch
			exit 0
		fi
	done
	
	# Remove garbage output files
	for i in merged.*; do
		[ -s $i ] && echo "Unexpected output, $i is non-zero" || rm $i
	done

	shopt -u nullglob
}


q2aReformat(){
	# DESCRIPTION: Reformats all fastq files in current directory to fasta

	# INPUTS: reformat.sh(), *.merged.fastq
	# OUTPUTS: *.merged.fasta

	# Deps: bbtools 'reformat' tool

	# NOTE: RUN AFTER: --- mergeSeqs
	#	RUN BEFORE: -- groupFormatter

	echo "asdMetagen: Reformatting merged fastqs files to fasta format..."
	for i in *.merged.fastq; do
		reformat.sh in=$i out=$(basename $i .fastq).fasta
	done

}


batchArrayadder(){
	# Description: Add fastas to array

	# INPUTS: $1, fasta_array, group_array 
	# OUTPUTS: fasta_array, group_array


	for i in $1; do
		echo "Adding $i to fastas array"
		fasta_array+=("$i")
		echo "Adding $AUTHOR\_${i%%.*} to groups array"
		group_array+=("$AUTHOR"_"${i%%.*}")
	done
}


groupFormatter(){
	# Description: Scans current directory for .fasta files, and
	#              formats them for use with the R package Mothur's
	#              'make.group()' command

	# INPUTS: batchArrayadder(), joinBy(), mothur(), fasta_array, group_array
	# OUTPUTS: $AUTHOR.groups, mothur.*.logfile

	# NOTE: RUN AFTER: --- q2a_reformat.sh
	# 	RUN BEFORE: -- [mothur merge script]

	# Ex: mothur > make.group(fasta=sample1.fasta-sample2.fasta-sample3.fasta, groups=A-B-C)

	OUT_FILE=$AUTHOR.groups
	for i in ${fasta_array[*]}; do
		echo "$i"
	done
	
	batchArrayadder "*.merged.fasta"	
	FORMATTER_FASTAS=$(joinBy - ${fasta_array[*]})
	FORMATTER_GROUPS=$(joinBy - ${group_array[*]})

	echo "make.group(fasta=$FORMATTER_FASTAS, groups=$FORMATTER_GROUPS)" \
		> group_batch.temp.txt
		
	mothur group_batch.temp.txt && rm group_batch.temp.txt

	# Rename output file to reflect author
	# 	(rather than the last group name, per mothur's default)
	echo "asdMetagen: renaming Output File -> $AUTHOR.groups"
	mv *merged.groups $AUTHOR.groups
	
	unset fasta_array
	unset group_array
}


trimLoop(){
	# Takes the primer patterns from command line,
	# inputs to cutadapt, and loops through all fasta # files in $(pwd)

	# INPUTS: cutadapt(), $FORPRIME, $REVPRIME, *.merged.fasta
	# OUTPUTS: *.trimmed.fasta

	echo "asdMetagen: Trimming primers..."
	echo "asdMetagen: FORPRIME = $FORPRIME\tREVPRIME = $REVPRIME"
	for x in *.merged.fasta; do
		m=${x%.fasta}
		cutadapt -g $FORPRIME -o $m.temp.fasta $x --discard-untrimmed
		cutadapt -a $REVPRIME -o $m.trimmed.fasta $m.temp.fasta --discard-untrimmed
	done
}


phixScreen(){
	# DESCRIPTION: Takes in a fasta file, phix databases in a directory named
	# 	$PWD/phix_db/ and screens for PhiX contamination

	# INPUTS: bowtie2(), *.trimmed.fasta
	# OUTPUTS: *.screened.fasta, *.merged.PhiX, *.merged.bowtie

	# Deps: bowtie2
	# Note: RUN AFTER: --- mothur > ~/code/shell/bioinf/screening_batch.txt
	#	RUN BEFORE: -- mothur > ~/code/shell/bioinf/phix_removal_batch.txt

	echo "asdMetagen: Screening for PhiX contamination"

	for i in *.trimmed.fasta; do
		bowtie2 -f $i -x phix_db/PhiX_bowtie_db \
			-S ${i%%.*}.merged.bowtie \
			--un ${i//trimmed/trimmed.screened} \
			--al ${i%%.*}.merged.PhiX \
			--local -p $THREADS
	done

	# Once complete, generate list of reads to be screened out
	for i in *.merged.PhiX; do
		if [[ -s $i ]]; then
			echo "generating PhiX accession number file..."

			# Old grep command, probably won't work on multiple
			# 	files without generating "<filename>:<accno>"
			# grep ">" *merged.PhiX >> PhiX.accnos

			# [Do accnos in *.merged.PhiX start with ">"?
			# 	also, this works with *.merged.PhiX,
			#	not just a single file "merged.PhiX"
			grep -Eo "[A-Z]{3,6}[0-9]+\.[0-9]+" *merged.bowtie \
			| awk -F: '{ print $2 }' >> PhiX.accnos
		else
			echo "asdMetagen: All *.merged.PhiX are empty, "\
				"skipping PhiX.accnos generation"
		fi
	done

	#if [ -s PhiX.accnos ]; then
	#    while IFS= ; do read line
	#                    grep -v -B 1 "$line" >> clean.merged.fasta
	#    done < PhiX.accnos
	#else echo "No PhiX detected, renaming merged.fasta for pipeline compatibility"
	#     mv merged.fasta clean.merged.fasta
	#fi

}


groupConcat(){
	# Concat all specified files and save to a defined output

	# INPUTS: *.fasta
	# OUTPUTS: $AUTHOR.concat.fasta

	for x in $1; do
		# Concat to fasta designated with authors name (from PWD)
		echo "asdMetagen: Adding $x to $2..."
		cat $x >> $2
	done
}


mothurScreen(){
	# Runs mothur against screening_batch.txt to screen concat'd fasta

	# INPUTS: mothur(), PhiX.accnos, $AUTHOR.concat.fasta,
	#		$AUTHOR.groups
	# OUTPUTS: *.good.count.summary, *.good.groups, *.good.fasta, 
	#		*.good.summary, *.bad.accnos

	SCREEN_FASTA=$AUTHOR.concat.fasta
	SCREEN_GROUPS=$AUTHOR.groups

	# Remove PhiX contamination
	if [ -s PhiX.accnos ]; then
		echo "remove.seqs(fasta=$SCREEN_FASTA, "\
			"group=$AUTHOR.groups, "\	# Not needed by mothur?
			"accnos=PhiX.accnos)" \
			>> phix_batch.txt
		mothur phix_batch.txt && \
		rm phix_batch.txt
	else
		echo "asdMetagen: PhiX.accnos is empty, skipping..."
	fi

	# Create screening_batch.txt
	echo "screen.seqs(fasta=$SCREEN_FASTA, group=$SCREEN_GROUPS, "\
		"minlength=200, maxlength=300, maxambig=0, maxhomop=8)" \
		> screening_batch.txt
	echo "summary.seqs(fasta=current, processors=$THREADS)" \
		>> screening_batch.txt
	echo "count.groups(group=current)" >> screening_batch.txt

	echo "asdMetagen: Dry-run of mothurScreen"
	echo "asdMetagen: cat'ing screening_batch.txt" 
	cat screening_batch.txt
	mothur screening_batch.txt && rm screening_batch.txt

#	mothurBatch screen seqs $SCREEN_PARAMS > screening_batch.txt
#	mothurBatch summary seqs $SUMMARY_PARAMS >> screening_batch.txt
#	mothurBatch count groups "group=current" >> screening_batch.txt 
}


mothurBatch(){
	# Wrapper script for generating simple mothur commands, prints
	# 	command to stdout to create batch files

	# Note: If you have many parameters, put them in an array!
	# Ex: EX_PARAMS+=(fasta=blah.fasta,"\
	#	group=blah.groups)
	#
	# Just make sure to refer to them with * expansion, not @ expansion
	# e.g. mothurBatch doggo play ${EX_PARAMS[*]}
	# 	|==> doggo.play(fasta=blah.fasta, group=blah.groups)

	COMMAND="$1.$2"
	PARAMS="$3"
	BATCH_FILE=$1_$2_batch.txt

	echo "$COMMAND($PARAMS)"
}


groupSplit(){
	# Splits the screened fasta to prepare for fasta header relabeling,
	# 	necessary for vsearch later

	GOOD_FASTA=$AUTHOR.concat.fasta
	GOOD_GROUPS=$AUTHOR.groups
	BATCH_FILE=split_batch.txt
	echo "GOOD_FASTA=$GOOD_FASTA, GOOD_GROUPS=$GOOD_GROUPS,"\
		"and BATCH_FILE=$BATCH_FILE"
	
	echo "split.groups(fasta=$GOOD_FASTA,"\
		"group=$GOOD_GROUPS)" > $BATCH_FILE
	mothur $BATCH_FILE
#	echo "asdMetagen: groupSplit dry run, cat'ing $BATCH_FILE"
#	cat $BATCH_FILE
	rm $BATCH_FILE

	# Rename output fastas to reasonable names
	for i in *.fasta; do
		if [[ "$i" =~ "concat.$AUTHOR" ]]; then
			# Remove everything up to "concat."
			# (i.e. result: author_year_accno.fasta)
			echo "asdMetagen: Renaming output files to"\
				"format: author_year_accno.fasta"
			mv $i ${i#*concat.}
		else
			continue
		fi
	done
}

fastaHeaderrelabel(){
	# Takes a fasta file labeled <author>_<year>_<accno>.fasta
	# 	and relabels headers for use with vsearch
	#
	# e.g.:
	# ">SRR10007909.1201 1201 length=251"
	# 		|
	# 		V
	# ">Li_2019_SRR10007909_1;barcodelabel=Li_2019_SRR10007909;"
		

	# INPUTS:  $AUTHOR_*.fasta
	# OUTPUTS: *.bar.fasta

	for i in "$AUTHOR"_*.fasta; do
		awk -v NAME_STRIPPED="${i%.fasta}" '{
			# Count every header line
			if (/^>/) COUNT+=1 

			# Define new header format
			VSEARCH_HEADER=">"NAME_STRIPPED"_"COUNT"\;barcodelabel="NAME_STRIPPED"\;"

			# Relabel everything after ">" with new header
			gsub(/^>.*/, VSEARCH_HEADER)
			print;
		}' $i > ${i%.fasta}.bar.fasta \
			# Suppress warning for "\;", that is intentional
			2>/dev/null
	done
}


derep(){
	# Dereplicate the barcoded fasta
	#
	# Poret-Peterson: 
	# 	"Singletons (OTUs represented 1 sequence) are discarded 
	# 	via the --minuniquesize command; setting this to 2 would 
	# 	generate OTUs represented by 2 or more sequences"
	
	vsearch --derep_fulllength $AUTHOR.barcoded.fasta --sizein --sizeout \
		--minuniquesize 2 --output $AUTHOR.derep.fasta
}


clusterOTUs(){
	# Cluster seqs into OTUs
	#
	# Poret-Peterson:
	#
	#	"Cluster sequences into OTUs (operational taxonomic units) at a
	#	97% cutoff (97% or more identity among sequences in an OTU). 
	#	Set threads to 40 in this example. This will need to be changed."

	vsearch --cluster_fast $AUTHOR.derep.fasta --id 0.97 \
		--centroids $AUTHOR.otus.fasta --uc $AUTHOR.otus.uc \
		--relabel OTU_ --sizein --sizeout --threads $THREADS
}

chimeraScreen(){
	# Screen for chimeric sequences
	vsearch --uchime_denovo $AUTHOR.otus.fasta --abskew 1.5 \
		--nonchimeras $AUTHOR.otus.nc.fasta --fasta_width 0
}

taxoClassify(){
	# Uses mothur to taxonomically classify OTUs
	# 	[Note: May need to update silva version prior to running ]
	TAXO_DB=$1
	TAXO_PARAMS+=("fasta=$AUTHOR.otus.nc.fasta,"\
		"template=$TAXO_DBsilva.nr_v128.U515F806R.pcr.good.ng.fasta,"\
		"taxonomy=$TAXO_DBsilva.nr_v128.U515F806R.pcr.good.tax,"\
		"cutoff=80")
	LINEAGE_PARAMS+=("fasta=$AUTHOR.otus.nc.fasta,"\
		"taxonomy=$AUTHOR.otus.nc.good.wang.taxonomy, taxon=unknown")
	mothurBatch classify seqs "${TAXO_PARAMS[*]}" > taxo_batch.txt
	mothurBatch remove lineage "${LINEAGE_PARAMS[*]}" >> taxo_batch.txt
	mothur taxo_batch.txt && rm taxo_batch.txt
}


mapOTUs(){
	# Maps OTUs against reads and converts them to an OTU table
	vsearch --usearch_global $AUTHOR.barcoded.fasta \
		-db $AUTHOR.otus.nc.pick.fasta \
		--uc $AUTHOR.otus.nc.readmap.uc --id 0.97 \
		--strand plus --threads $THREADS &
}


readmap2file(){
	# Convert the readmap to an OTU table
	# [ I don't have this python2 file? Also, there's gotta be a way to
	# 	do this with at least python3. Probably possible with Bash...]
	python2.7 create_otu_table_from_uc_file.py \
		-i $AUTHOR.otus.nc.readmap.uc \
		-o $AUTHOR.otus.final.readmap.table
}


# Main

pathTester cutadapt cutadapt
pathTester bbmap bbmerge.sh
pathTester sratoolkit fastq-dump
pathTester mothur mothur
pathTester mothur vsearch
sraFinder
srrMunch
16sExtractor
mergeSeqs
q2aReformat
groupFormatter # [New Position; was after phix, before groupConcat]
trimLoop
phixScreen
groupConcat "*trimmed*fasta" "$AUTHOR.concat.fasta"
mothurScreen
groupSplit
fastaHeaderrelabel
groupConcat "*bar.fasta" "$AUTHOR.barcoded.fasta"
#derep 
#clusterOTUs
#chimeraScreen
#taxoClassify 
#mapOTUs
#readmap2file
