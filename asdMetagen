#!/bin/bash
# sraFinder.sh

# AUTHOR: Samuel Johnson
# LICENSE: GNU Affero General Public License https://www.gnu.org/licenses/agpl-3.0.html
# DEPENDS: poppler-utils, bash

# Set input files
RUNTABLE=SraRunTable.txt
ACCESSION_LIST=SRR_Acc_List.txt

# Set primers
FORPRIME=$1
REVPRIME=$2

# Define use flags
while getopts "h" FLAGS; do
	case $FLAGS in
		h)
			echo "asdMetagen: Usage: ./asdMetagen <forward primer> <reverse primer>"
			exit;;
	esac
done

nucRegex(){
	# Convert degenerate bases to regex patterns

	echo $1 | sed '
	s/W/(A|T)/
	s/S/(C|T)/
	s/M/(A|C)/
	s/K/(G|T)/
	s/R/(A|G)/
	s/Y/(C|T)/
	s/B/[CGT]/
	s/D/[AGT]/
	s/H/[ACT]/
	s/V/[ACG]/
	s/N/./
	s/X/./
	'
}

sraFinder(){
	# Simple grep parser for all NCBI SRA accession numbers in pdf files in the working directory
	# usage: <sraFinder.sh>

	shopt -s nullglob
	if [[ ! -z $(ls | grep \.pdf) ]]; then
		for f in *.pdf; do
			pdftotext $f # convert pdf files to parsable txt files
			r=$(echo $f | sed 's/\.pdf/.txt/')
			if [[ ! -z $(grep -Eo "[A-Z]{3,}[[:digit:]]{5,}" $r) ]]; then
				cat $r | grep -Eo "[A-Z]{3,}[[:digit:]]{5,}" $r > \
					$(echo $r | sed 's/\.txt//').sra
				# echo anything in txt that has =>3 capitals, followed
				# 	by => 5 numbers, into a new file with a ".sra"
				# 	extension (regex: [A-Z]{3,}[[:digit:]]{5,} )
			else
				echo "No valid accession number found in file: $f"
			fi

			# Make primers file for screening [WORK IN PROGRESS]
			grep -i -P -A 1 "[0-9]{3}f" > $(basename -- $f .pdf)_primers.txt
			grep -i -P -A 1 "[0-9]{3}r" >> $(basename -- $f .pdf)_primers.txt
			rm $r
		done
	else
		echo "Error: no valid .pdf files found in this directory!"
	fi

	shopt -u nullglob
}

# TO DO

# Perform web search (maybe with curl, lynx?) for SRA/PRJNA/etc number,
# 	bypass writing to a separate file, and autodownload SRA
#	accession list, etc.
#
# 	https://www.ncbi.nlm.nih.gov/sra/?term=<SRA NUMBER HERE>
#
# 	Must grab from run selector! e.g. for https://www.ncbi.nlm.nih.gov/bioproject/PRJNA561262
# 	Dang it, I can't find anything for the specific buttons for RunTableInfo and Accession List;
#	I don't know enough javascript to figure out how to connect to what those buttons do. Maybe
# 	NCBI has a CLI for grabbing this stuff?
#	Oh, it'd be a good idea to confirm the SRAs etc. grabbed from each paper before grabbing those
#	docs. So it'd have to be interactive....maybe this would be a good project to learn some
#	GUI skills for...

sufRegex(){
	# Takes in unmerged fastq ending in _1|_R1,
	# 	and returns suffic regex and the name
	# 	of the reverse read

	if [[ "$1" =~ "_1.fastq" ]]; then
		SUF_REGX="s/_1\.fastq/_2.fastq/"
	elif [[ "$1" =~ "_R1.fastq" ]]; then
		SUF_REGX="s/_R1\.fastq/_R2.fastq/"
	else
		echo "asdMetagen: Error: Expected merge suffices not found" >&2
		exit 1
	fi
	echo "asdMetagen: Suffix Regex: $SUF_REGX"
	REV=$(echo "$1" | sed $SUF_REGX)
}

srrMunch(){
	# Short script to loop through SRRs in an SRA list, running fastq-dump, and
	# 	nicely formatting them with bbtools' reformat.sh (for now, with manual
	#	read number relabeling).

	# Old snippet to run on default output file from NCBI (SRR_Acc_List.txt)
	shopt -s nullglob

	while read x; do
		if [ -f "$x.fastq.gz" ]; then
			# in case the download glitches and needs to be re-run
			continue
		else
        		#fastq-dump --split-3 --gzip $x
			fastq-dump --split-files --gzip $x
			gzip -d $(basename $x .fastq.gz)*.fastq
			FORWARD="$(basename $x)*_*1.fastq"
		fi
	done < $ACCESSION_LIST

	shopt -u nullglob
}


16sExtractor(){
	# Description: takes an SraRunTable file from NCBI and outputs all
	# 		SRR's that contain "16S"

	mkdir 16S_temp filter
	if [ -f $RUNTABLE ]; then
		# create list of 16S seqs from the runtable
		awk -F "," '/16S/ { print $1 }' $RUNTABLE > 16S_list.txt.temp
		while read line; do
			echo "$line.fastq"
			eval mv $line*.fastq 16S_temp # move 16S seqs to temp dir
		done < 16S_list.txt.temp
		rm 16S_list.txt.temp
		mv *.fastq filter	# move the non-match seqs to the filter
		mv 16S_temp/* . && rmdir 16S_temp
	else
		echo "No SraRunTable.txt found! Try grep -B 1 -E \"<FORWARD PRIMER>\" on fastqs"
		echo "\nExample output:"
		grep -EB 1 $(nucRegex $FORPRIME)
		# Put grep tool for generating 16S list here
		# 	(Note: Add both "FPRIMER" __and__ "^FPRIMER" versions, and separate
		# 	their results in different directories)
	#	        head -n 2 *.fastq \
	#	        | grep -EB 1 $FPRIMER \
	#	        | grep -o "SRR[0-9]\+" \
	#	        | sed 's/$/.fastq/'
	        echo "Error: No fastq files found in current directory"
	fi
}


mergeSeqs(){
	# DESCRIPTION: A simple script that runs bbmerge.sh to merge all fastqs in the current
	# 	directory.

	# Deps: bbmerge.sh
	# NOTE: RUN AFTER: --- srr_munch.sh
	#	RUN BEFORE: -- q2a_reformat.sh

	shopt -s nullglob

	# Merge all _1 & _2 fastqs
	for i in *1.fastq; do
		sufRegex $i		
		READ_NAME=$(basename $i _1.fastq) # genericize to _1 or _R1 later?
		OUT_FILE=$(echo "$i" | sed 's/_\(\|R\)1\.fastq/.merged/')

		# Make sure the read numbers are identical between forward
		# 	and reverse
		echo "Checking: $i" "$REV"
		F_READ_NUM=$(grep -c "@$READ_NAME" $i)
		R_READ_NUM=$(grep -c "@$READ_NAME" $REV)

		if [[ "$F_READ_NUM" == "$R_READ_NUM" ]]; then
			echo "asdMetagen: Read counts match; Now merging: $i" "$REV"
			echo "asdMetagen: Merge out file: $OUT_FILE"
			bbmerge.sh in1="$i" in2="$REV" out="$OUT_FILE"
		else
			echo "Mismatch found, delete reads for $READ_NAME and \
				re-run fastq-dump before proceeding"
			# rm $i $REV && srrMunch
			# exit 0
		fi
		done
	
	# Remove garbage output files
	for i in merged.*; do
		[ -s $i ] && echo "Unexpected output, $i is non-zero" || rm $i
	done

	shopt -u nullglob
}


q2aReformat(){
	# DESCRIPTION: Reformats all fastq files in current directory to fasta

	# Deps: bbtools 'reformat' tool

	# NOTE: RUN AFTER: --- flash2_merge.sh
	#	RUN BEFORE: -- groupFormatter.sh

	if [ -z $(type -P reformat.sh) ] && [ -f reformat.sh ]; then
		COMMAND="./reformat.sh"
	elif [ ! -z $(type -P reformat.sh) ]; then
		COMMAND="reformat.sh"
	fi

	for i in *.merged; do
		$COMMAND in=$i out=$(basename $i .merged).fasta
	done

}


trim_loop(){
	# Takes the primer patterns from command line,
	# inputs to cutadapt, and loops through all fasta # files in $(pwd)

	# Load cutadapt if necessary
	#if [ -z $(command -v cutadapt) ]; then
	#    module load cutadapt/2.0 # comment out when on local machine!
	#else
	#    echo "cutadapt not found in PATH or module list" && exit 1
	#fi


	# Loop over merged fastas
	echo "asdMetagen: FORPRIME = $FORPRIME\t REVPRIME = $REVPRIME"
	for x in *.fasta; do
		m=$(basename $x .fasta)

		cutadapt -g $FORPRIME -o $m.temp.fasta $x --discard-untrimmed
		cutadapt -a $REVPRIME -o $m.trimmed.fasta $m.temp.fasta --discard-untrimmed

	done
}


phixTrim(){
	# DESCRIPTION: Takes in a fasta file, phix databases in a directory named
	# 	$PWD/phix_db/ and screens for PhiX contamination

	# Deps: bowtie2
	# Note: RUN AFTER: --- mothur > ~/code/shell/bioinf/screening_batch.txt
	#	RUN BEFORE: -- mothur > ~/code/shell/bioinf/phix_removal_batch.txt



	  bowtie2 -x phix_db/PhiX_bowtie_db -f -U *merged.fasta -S merged.bowtie \
            --un merged.screened --al merged.PhiX --local -p 2

	echo "PhiX screened, generating PhiX accession number file..."
	grep ">" merged.PhiX >> PhiX.accnos

	#if [ -s PhiX.accnos ]; then
	#    while IFS= ; do read line
	#                    grep -v -B 1 "$line" >> clean.merged.fasta
	#    done < PhiX.accnos
	#else echo "No PhiX detected, renaming merged.fasta for pipeline compatibility"
	#     mv merged.fasta clean.merged.fasta
	#fi
}


groupConcat(){
	# group_concat.sh
	# Concat all *trimmed*fasta files in current directory

	for x in *trimmed*; do
		#echo "Dry run of cat $x to $(basename $x | sed 's/_.*$//').trimmed.concat.fasta"
		cat $x >> $(basename $x | sed 's/_.*$//').trimmed.concat.fasta
	done
}


groupFormatter(){
	# Description: Scans current directory for .fasta files, and
	#              formats them for use with the R package Mothur's
	#              'make.group()' command

	# NOTE: RUN AFTER: --- q2a_reformat.sh
	# 	RUN BEFORE: -- [mothur merge script]

	# Ex: mothur > make.group(fasta=sample1.fasta-sample2.fasta-sample3.fasta, groups=A-B-C)

	for i in *.fasta; do
		echo "$i" >> groups.temp
	done

	tr "\n" "-" < groups.temp > group_paren.txt
	rm groups.temp
	echo "make.group($(cat group_paren.txt))" | sed s/-\)$/\)/ > group_batch.txt
	./mothur group_batch.txt
}


mothurScreen(){
	# Runs mothur against screening_batch.txt to screen concat'd fasta

	echo "screen.seqs(fasta=merged.pick.fasta, group=merged.pick.groups, minlength=200, maxlength=300, maxambig=0, maxhomop=8)" > screening_batch.txt
	echo "summary.seqs(fasta=current, processors=20)" >> screening_batch.txt
	echo "count.groups(group=current)" >> screening_batch.txt
	./mothur screening_batch.txt
	rm screening_batch.txt
}
#grep -Eo "[A-Z]{3,6}[0-9]{4,6}" ../usda/docs/pdf/Hewavitharana_etal_2019_Temporal_Dynamics_ASD_metabolome.txt
#https://www.ncbi.nlm.nih.gov/search/all/\?term\=PRJNA561262
#https://www.ncbi.nlm.nih.gov/bioproject/PRJNA561262
#https://www.ncbi.nlm.nih.gov/sra\?linkname\=bioproject_sra_all\&from_uid\=561262
#https://www.ncbi.nlm.nih.gov/Traces/study/\?WebEnv\=NCID_1_91785073_130.14.22.33_5555_1583974610_681314290_0MetA0_S_HStore\&query_key\=2
#https://www.ncbi.nlm.nih.gov/Traces/study/\?query_key\=2\&WebEnv\=NCID_1_91785073_130.14.22.33_5555_1583974610_681314290_0MetA0_S_HStore\&o\=acc_s%3Aa


# Main
if [ ! -f "SRR_Acc_List.txt" ] && [ ! -f "SraRunTable.txt" ]; then
	sraFinder	# [WORKING]
else
	echo "asdMetagen: Accession List and Run Table found, continuing..."
fi

#srrMunch 	# [BROKEN? fastq-dump READLEN > 1 error]
#16sExtractor 	# [WORKING]
#mergeSeqs 	# [WORKING]
#q2aReformat 	# [WORKING]
trim_loop	# [BROKEN? Most, but not all, reads tossed by cutadapt]
#phixTrim	# []
#groupConcat	# []
#groupFormatter	# []
#mothurScreen	# []
